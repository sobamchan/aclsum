{
    "paper_id": "2022",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:15:48.918759Z"
    },
    "title": "The Paradox of the Compositionality of Natural Language: A Neural Machine Translation Case Study",
    "authors": [
        {
            "first": "Verna",
            "middle": [],
            "last": "Dankers",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Edinburgh",
                "location": {}
            },
            "email": "vernadankers@gmail.com"
        },
        {
            "first": "Elia",
            "middle": [],
            "last": "Bruni",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Osnabr\u00fcck",
                "location": {}
            },
            "email": "elia.bruni@gmail.com"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Obtaining human-like performance in NLP is often argued to require compositional generalisation. Whether neural networks exhibit this ability is usually studied by training models on highly compositional synthetic data. However, compositionality in natural language is much more complex than the rigid, arithmeticlike version such data adheres to, and artificial compositionality tests thus do not allow us to determine how neural models deal with more realistic forms of compositionality. In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT). Our results highlight that: i) unfavourably, models trained on more data are more compositional; ii) models are sometimes less compositional than expected, but sometimes more, exemplifying that different levels of compositionality are required, and models are not always able to modulate between them correctly; iii) some of the non-compositional behaviours are mistakes, whereas others reflect the natural variation in data. Apart from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math. 1",
    "pdf_parse": {
        "paper_id": "2022",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Obtaining human-like performance in NLP is often argued to require compositional generalisation. Whether neural networks exhibit this ability is usually studied by training models on highly compositional synthetic data. However, compositionality in natural language is much more complex than the rigid, arithmeticlike version such data adheres to, and artificial compositionality tests thus do not allow us to determine how neural models deal with more realistic forms of compositionality. In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT). Our results highlight that: i) unfavourably, models trained on more data are more compositional; ii) models are sometimes less compositional than expected, but sometimes more, exemplifying that different levels of compositionality are required, and models are not always able to modulate between them correctly; iii) some of the non-compositional behaviours are mistakes, whereas others reflect the natural variation in data. Apart from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math. 1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Although the successes of deep neural networks in natural language processing (NLP) are astounding and undeniable, they are still regularly criticised for lacking the powerful generalisation capacities that characterise human intelligence. A frequently mentioned concept in such critiques is compositionality: the ability to build up the meaning of a complex expression by combining the meanings of its parts (e.g. Partee, 1984) . Compositionality is assumed to play an essential role in how humans understand language, but whether neural networks also exhibit this property has since long been a topic of vivid debate (e.g. Fodor and Pylyshyn, 1988; Smolensky, 1990; Marcus, 2003; Nefdt, 2020) .",
                "cite_spans": [
                    {
                        "start": 415,
                        "end": 428,
                        "text": "Partee, 1984)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 625,
                        "end": 650,
                        "text": "Fodor and Pylyshyn, 1988;",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 651,
                        "end": 667,
                        "text": "Smolensky, 1990;",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 668,
                        "end": 681,
                        "text": "Marcus, 2003;",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 682,
                        "end": 694,
                        "text": "Nefdt, 2020)",
                        "ref_id": "BIBREF24"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Studies about the compositional abilities of neural networks consider almost exclusively models trained on synthetic datasets, in which compositionality can be ensured and isolated (e.g. Lake and Baroni, 2018; Hupkes et al., 2020) . 2 In such tests, the interpretation of expressions is computed completely locally: every subpart is evaluated independently -without taking into account any external context -and the meaning of the whole expression is then formed by combining the meanings of its parts in a bottom-up fashion. This protocol matches the type of compositionality observed in arithmetic: the meaning of (3 + 5) is always 8, independent of the context it occurs in.",
                "cite_spans": [
                    {
                        "start": 187,
                        "end": 209,
                        "text": "Lake and Baroni, 2018;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 210,
                        "end": 230,
                        "text": "Hupkes et al., 2020)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "However, as exemplified by the sub-par performance of symbolic models that allow only strict, local protocols, compositionality in natural domains is far more intricate than this rigid, arithmeticlike variant of compositionality. Natural language seems very compositional, but at the same time, it is riddled with cases that are difficult to interpret with a strictly local interpretation of compositionality. Sometimes, the meaning of an expression does not derive from its parts (e.g. for idioms), but the parts themselves are used compositionally in other contexts. In other cases, the meaning of an expression does depend on its parts in a compositional way, but arriving at this meaning requires a more global approach because the meanings of the parts need to be disambiguated by information from elsewhere. For instance, consider the meaning of homonyms (\"these dates are perfect for our dish/wedding\"), potentially idiomatic expressions (\"the child kicked the bucket off the pavement\"), or scope ambiguities (\"every human likes a cat\"). This paradoxical tension between local and global forms of compositionality inspired many debates on the compositionality of natural language. Likewise, it impacts the evaluation of compositionality in NLP models. On the one hand, local compositionality seems necessary for robust and reliable generalisation. Yet, at the same time, global compositionality is needed to appropriately address the full complexity of language, which makes evaluating compositionality of state-of-the-art models 'in the wild' a complicated endeavour.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this work, we face this challenge head-on. We concentrate on the domain of neural machine translation (NMT), which is paradigmatically close to the tasks typically considered for compositionality tests, where the target represents the 'meaning' of the input. 3 Furthermore, MT is an important domain of NLP, for which compositional generalisation is important to produce more robust translations and train adequate models for low-resource languages (see, e.g. Chaabouni et al., 2021) . As an added advantage, compositionality is traditionally well studied and motivated for MT (Rosetta, 1994; Janssen and Partee, 1997; Janssen, 1998) .",
                "cite_spans": [
                    {
                        "start": 463,
                        "end": 486,
                        "text": "Chaabouni et al., 2021)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 580,
                        "end": 595,
                        "text": "(Rosetta, 1994;",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 596,
                        "end": 621,
                        "text": "Janssen and Partee, 1997;",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 622,
                        "end": 636,
                        "text": "Janssen, 1998)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We reformulate three theoretically grounded tests from Hupkes et al. (2020) : systematicity, substitutivity and overgeneralisation. Since accuracycommonly used in artificial compositionality testsis not a suitable evaluation metric for MT, we base our evaluations on the extent to which models behave consistently, rather than correctly. In our tests for systematicity and substitutivity, we consider whether processing is local; in our overgeneralisation test, we consider how models treat idioms that are assumed to require global processing.",
                "cite_spans": [
                    {
                        "start": 55,
                        "end": 75,
                        "text": "Hupkes et al. (2020)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Our results indicate that models often do not behave compositionally under the local interpretation, but exhibit behaviour that is too local in other cases. In other words, models have the ability to process phrases both locally and globally but do not always correctly modulate between them. We further show that some inconsistencies reflect variation in natural language, whereas others are true compositional mistakes, exemplifying the need for both local and global compositionality as well as illustrating the need for tests that encompass them both.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "With our study, we contribute to ongoing questions about the compositional abilities of neural networks, and we provide nuance to the nature of this question when natural language is concerned: how local should the compositionality of models for natural language actually be? Aside from an empirical study, our work is also a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Tests for compositional generalisation in neural networks typically assume an arithmetic-like version of compositionality, in which meaning can be computed bottom up. The compositions require only local information -they are context independent and unambiguous: \"walk twice after jump thrice\" (a fragment from SCAN by Lake and Baroni, 2018) is evaluated similarly to (2 + 1) \u00d7 (4 -5). In MT, this type of compositionality would imply that a change in a word or phrase should affect only the translation of that word or phrase, or at most the smallest constituent it is a part of. For instance, the translation of \"the girl\" should not change depending on the verb phrase that follows it, and in the translation of a conjunction of two sentences, making a change in the first conjunct should not change the translation of the second. While translating in such a local way seems robust and productive, it is not always realistic -e.g. consider the translation of \"dates\" in \"She hated bananas and she liked dates\".",
                "cite_spans": [
                    {
                        "start": 318,
                        "end": 340,
                        "text": "Lake and Baroni, 2018)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Local and global compositionality",
                "sec_num": "2"
            },
            {
                "text": "In linguistics and philosophy of language, the level of compositionality has been widely discussed, which led to a variety of definitions. One of the most well-known ones is from Partee (1984) :",
                "cite_spans": [
                    {
                        "start": 179,
                        "end": 192,
                        "text": "Partee (1984)",
                        "ref_id": "BIBREF28"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Local and global compositionality",
                "sec_num": "2"
            },
            {
                "text": "\"The meaning of a compound expression is a function of the meanings of its parts and of the way they are syntactically combined.\" 4This definition hardly places restrictions on the relationship between expressions and their parts. The type of function that relates them is unspecified and could take into account the global syntactic structure or external arguments, and the parts' meanings can depend on global information. Partee's definition is therefore called weak, global, or open compositionality (Szab\u00f3, 2012; Garc\u00eda-Ram\u00edrez, 2019) . When, instead, the meaning of a compound depends only on the meanings of its largest parts, regardless of their internal structure (similar to arithmetic), that is strong, local or closed n Template",
                "cite_spans": [
                    {
                        "start": 504,
                        "end": 517,
                        "text": "(Szab\u00f3, 2012;",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 518,
                        "end": 539,
                        "text": "Garc\u00eda-Ram\u00edrez, 2019)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Local and global compositionality",
                "sec_num": "2"
            },
            {
                "text": "The Npeople V the N sl people . 2",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople Adv V the N sl people . 3",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople P the N sl vehicle V the N sl people . 4",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople and the Npeople V the N sl people . 5",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The N sl quantity of N pl people P the N sl vehicle V the N sl people . 6",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople V that the N pl people V. 7",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople Adv V that the N pl people V . 8",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople V that the N pl people V Adv . 9",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople that V V the N sl people . 10 The Npeople that V Pro V the N sl people .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "(a) Synthetic templates",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "n Template 1,2,3",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople VP1,2,3 . The men are gon na have to move off-camera .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "1",
                "sec_num": null
            },
            {
                "text": "The Npeople read(s) an article about NP1,2 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "4,5",
                "sec_num": null
            },
            {
                "text": "The man reads an article about the development of ascites in rats with liver cirrhosis .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "4,5",
                "sec_num": null
            },
            {
                "text": "An article about NP3,4 is read by Npeople .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6,7",
                "sec_num": null
            },
            {
                "text": "An article about the criterion on price stability , which was 27 % , is read by the child . 8,9,10 Did the Npeople hear about NP5,6,7 ?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6,7",
                "sec_num": null
            },
            {
                "text": "Did the teacher hear about the march on Employment which happened here on Sunday ? compositionality (Jacobson, 2002; Szab\u00f3, 2012) . Under the local interpretation, natural language can hardly be considered compositional -many frequent phenomena such as homonyms, idioms and scope ambiguities cannot be resolved locally (Pagin and Westerst\u00e5hl, 2010; Pavlick and Callison-Burch, 2016) . The global interpretation handles such cases straightforwardly but does not match up with many a person's intuitions about the compositionality of language. After all, how useful is compositionality if composing the meanings of parts requires the entire rest of the sentence? This paradox inspired debates on the compositionality of natural language and is also highly relevant in the context of evaluating compositionality in neural models.",
                "cite_spans": [
                    {
                        "start": 100,
                        "end": 116,
                        "text": "(Jacobson, 2002;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 117,
                        "end": 129,
                        "text": "Szab\u00f3, 2012)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 319,
                        "end": 348,
                        "text": "(Pagin and Westerst\u00e5hl, 2010;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 349,
                        "end": 382,
                        "text": "Pavlick and Callison-Burch, 2016)",
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6,7",
                "sec_num": null
            },
            {
                "text": "(b) Semi-natural templates",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6,7",
                "sec_num": null
            },
            {
                "text": "Previous compositionality tests ( \u00a76) considered only the local interpretation of compositionality, but to what extent is that relevant given the type of compositionality actually required to model natural language? Here, we aim to open up the discussion about what it means for computational models of language to be compositional by considering properties that require composing meaning locally as well as globally and evaluating them in models trained on unadapted natural language corpora.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6,7",
                "sec_num": null
            },
            {
                "text": "We focus on English-Dutch translation, for which we can ensure good command for both languages. We train Transformer-base models (Vaswani et al., 2017) using Fairseq (Ott et al., 2019) . Our training data consists of a collection of MT corpora bundled in OPUS (Tiedemann and Thottingal, 2020) , of which we use the English-Dutch subset provided by Tiedemann (2020) , which contains 69M sentence pairs.5 To examine the impact of the amount of training data -a dimension that is relevant because compositionality is hypothesised to be more important when resources are scarcer -we train one setup using the full dataset, one using 1 8 of the data (medium), and one using one million sourcetarget pairs in the small setup. For each setup, we train models with five seeds and average the results.",
                "cite_spans": [
                    {
                        "start": 129,
                        "end": 151,
                        "text": "(Vaswani et al., 2017)",
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 166,
                        "end": 184,
                        "text": "(Ott et al., 2019)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 260,
                        "end": 292,
                        "text": "(Tiedemann and Thottingal, 2020)",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 348,
                        "end": 364,
                        "text": "Tiedemann (2020)",
                        "ref_id": "BIBREF40"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model and training",
                "sec_num": "3.1"
            },
            {
                "text": "To evaluate our trained models, we adopt FLORES-101 (Goyal et al., 2021) , which contains 3001 sentences from Wikinews, Wikijunior and WikiVoyage, translated by professional translators, split across three subsets. We train the models until convergence on the 'dev' set. Afterwards, we compute SacreBLEU scores on the 'devtest' set (Post, 2018) , using beam search (beam size = 5), yielding scores of 20.6\u00b1.4, 24.4\u00b1.3 and 25.8\u00b1.1 for the small, medium and full datasets, respectively.6 ",
                "cite_spans": [
                    {
                        "start": 52,
                        "end": 72,
                        "text": "(Goyal et al., 2021)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 332,
                        "end": 344,
                        "text": "(Post, 2018)",
                        "ref_id": "BIBREF32"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model and training",
                "sec_num": "3.1"
            },
            {
                "text": "While all our models are trained on fully natural data, for evaluation we use different types of data: synthetic, semi-natural and natural data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation data",
                "sec_num": "3.2"
            },
            {
                "text": "Synthetic data For our synthetic evaluation data, we consider the data generated by Lakretz et al. (2019) , previously used to probe for hierarchical structure in neural language models. This data consist of sentences with a fixed syntactic structure and diverse lexical material. We extend the vocabulary and the templates used to generate the data and generate 3000 sentences for each of the resulting 10 templates (see Table 1a ).",
                "cite_spans": [
                    {
                        "start": 84,
                        "end": 105,
                        "text": "Lakretz et al. (2019)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 428,
                        "end": 430,
                        "text": "1a",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Evaluation data",
                "sec_num": "3.2"
            },
            {
                "text": "Semi-natural data In the synthetic data, we have full control over the sentence structure and lexical items, but the sentences are shorter (9 tokens vs 16 in OPUS) and simpler than typical in NMT data. To obtain more complex yet plausible test sentences, we employ a data-driven approach The girl sees that the men cry",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation data",
                "sec_num": "3.2"
            },
            {
                "text": "The girl sees that the men cry , and the poet criticises the king S\u2192S CONJ S NP\u2192NP'",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation data",
                "sec_num": "3.2"
            },
            {
                "text": "The painter avoids the mayor , and the poet criticises the king",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation data",
                "sec_num": "3.2"
            },
            {
                "text": "The baker sees that the men cry The girl sees that the aunts cry",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "S\u2192NP VP",
                "sec_num": null
            },
            {
                "text": "The girl sees that the men cry VP\u2192VP' to generate semi-natural data. Using the tree substitution grammar Double DOP (Van Cranenburgh et al., 2016) , we obtain noun and verb phrases (NP, VP) whose structures frequently occur in OPUS.",
                "cite_spans": [
                    {
                        "start": 116,
                        "end": 146,
                        "text": "(Van Cranenburgh et al., 2016)",
                        "ref_id": "BIBREF42"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "S\u2192NP VP",
                "sec_num": null
            },
            {
                "text": "We then embed these NPs and VPs in ten synthetic templates with 3000 samples each (see Table 1b ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 93,
                        "end": 95,
                        "text": "1b",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "S\u2192NP VP",
                "sec_num": null
            },
            {
                "text": "See Appendix A for details on the data generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "S\u2192NP VP",
                "sec_num": null
            },
            {
                "text": "Natural data Lastly, we extract natural data directly from OPUS, as detailed in the subsections of the individual tests ( \u00a74).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "S\u2192NP VP",
                "sec_num": null
            },
            {
                "text": "In our experiments, we consider systematicity ( \u00a74.1) and substitutivity ( \u00a74.2), to test for local compositionality, and idiom translation to probe for a more global type of processing ( \u00a74.3).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments and results",
                "sec_num": "4"
            },
            {
                "text": "One of the most commonly tested properties of compositional generalisation is systematicity -the ability to understand novel combinations made up from known components (most famously, Lake and Baroni, 2018) . In natural data, the number of potential recombinations to consider is infinite. We chose to focus on recombinations in two sentence-level context-free rules: S \u2192 NP VP and S \u2192 S CONJ S.",
                "cite_spans": [
                    {
                        "start": 184,
                        "end": 206,
                        "text": "Lake and Baroni, 2018)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Systematicity",
                "sec_num": "4.1"
            },
            {
                "text": "Test design The first setup, S \u2192 NP VP, concerns recombinations of noun and verb phrases. We extract translations for input sentences from the templates from \u00a73.2, as well as versions of them with the (1) noun (NP \u2192 NP') or (2) verb phrase (VP \u2192 VP') adapted. In (1), a noun from the NP in the subject position is replaced with a different noun while preserving number agreement with the VP. In (2), a noun in the VP is replaced. NP \u2192 NP' is applied to both synthetic and semi-natural data; VP \u2192 VP' only to synthetic data. We use 500 samples per template per condition per data type.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.1.1"
            },
            {
                "text": "The second setup, S \u2192 S CONJ S, involves phrases concatenated using \"and\", and tests whether the translation of the second sentence is dependent on the first sentence. We concatenate two sentences (S 1 and S 2 ) from different templates, and we consider again two different conditions. First, in condition S 1 \u2192 S 1 , we make a minimal change to S 1 yielding S 1 by changing the noun in its verb phrase. In S 1 \u2192 S 3 , instead, we replace S 1 with a sentence S 3 that is sampled from a template different from S 1 . We compare the translation of S 2 in all conditions. For consistency, the first conjunct is always sampled from the synthetic data templates. The second conjunct is sampled from synthetic data, semi-natural data, or from natural sentences sampled from OPUS with similar lengths and word-frequencies as the semi-natural inputs. We use 500 samples per template per condition per data type. Figure 2 provides an illustration of the different setups experimented with.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 911,
                        "end": 912,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.1.1"
            },
            {
                "text": "Evaluation In artificial domains, systematicity is evaluated by leaving out combinations of 'known components' from the training data and using them for testing purposes. The necessary familiarity of the components (the fact that they are 'known') is ensured by high training accuracies, and systematicity is quantified by measuring the test set accu- racy. If the training data is a natural corpus and the model is evaluated with a measure like BLEU in MT, this strategy is not available. We observe that being systematic requires being consistent in the interpretation assigned to a (sub)expression across contexts, both in artificial and natural domains. Here, we, therefore, focus on consistency rather than accuracy, allowing us to employ a modeldriven approach that evaluates the model's systematicity as the consistency of the translations when presenting words or phrases in multiple contexts.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.1.1"
            },
            {
                "text": "We measure consistency as the equality of two translations after accounting for anticipated changes. For instance, in the S \u2192 NP VP setup, two translations are consistent if they differ in one word only, after accounting for determiner changes in Dutch (\"de\" vs \"het\"). In the evaluation of S \u2192 S CONJ S, we measure the consistency of the translations of the second conjunct.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.1.1"
            },
            {
                "text": "Figure 1 shows the results for the S \u2192 NP VP and S \u2192 S CONJ S setups (numbers available in Appendix B). The average performance for the natural data closely resembles the performance on seminatural data, suggesting that the increased degree of control did not severely impact the results obtained using this generated data. 7 In general, the consistency scores are low, illustrating that models are prone to changing their translation of a (sub)sentence after small (unrelated) adaptations to the input. It hardly matters whether that change occurs in the sentence itself (S \u2192 NP VP), or in the other conjunct (S \u2192 S CONJ S), suggesting that the processing of the models is not local as assumed in strong compositionality. Models trained on more data seem more locally compositional, a somewhat contradictory solution to achieving compositional-ity, which, after all, is assumed to underlie the ability to generalise usage from few examples (Lake et al., 2019) . This trend is also at odds with the hypothesis that inconsistencies are a consequence of the natural variation of language, which models trained on more data are expected to better capture.",
                "cite_spans": [
                    {
                        "start": 941,
                        "end": 960,
                        "text": "(Lake et al., 2019)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.1.2"
            },
            {
                "text": "Under a local interpretation of the principle of compositionality, synonym substitutions should be meaning-preserving: substituting a constituent in a complex expression with a synonym should not alter the complex expression's meaning, or, in the case of MT, its translation. Here, we test to what extent models' translations abide by this principle, by performing the substitutivity test from Hupkes et al. (2020) , that measures whether the outputs remain consistent after synonym substitution.",
                "cite_spans": [
                    {
                        "start": 394,
                        "end": 414,
                        "text": "Hupkes et al. (2020)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Substitutivity",
                "sec_num": "4.2"
            },
            {
                "text": "To find synonyms -source terms that translate into the same target terms -we exploit the fact that OPUS contains texts both in British and American English. Therefore, it contains synonymous terms that are spelt different -e.g. \"doughnut\" / \"donut\"and synonymous terms with a very different forme.g. \"aubergine\" / \"eggplant\". We use 20 synonym pairs in total (see Figure 3b ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 371,
                        "end": 373,
                        "text": "3b",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.2.1"
            },
            {
                "text": "Test design Per synonym pair, we select natural data from OPUS in which the terms appear and perform synonym substitutions. Thus, each sample has two sentences, one with the British and one with the American English term. We also insert the synonyms into the synthetic and semi-natural data using 500 samples per synonym pair per template, through subordinate clauses that modify a noun -e.g. \"the king that eats the doughnut\". In Appendix C, Table 6 , we list all clauses used.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 449,
                        "end": 450,
                        "text": "6",
                        "ref_id": "TABREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.2.1"
            },
            {
                "text": "Evaluation Like systematicity, we evaluate substitutivity using the consistency score, expressing whether the model translations for a sample are identical. We report both the full sentence consistency and the consistency of the synonyms' translations only, excluding the context. Cases in which the model omits the synonym from both translations are labelled as consistent if the rest of the translation is the same for both input sequences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.2.1"
            },
            {
                "text": "In Figure 3a , we summarise all substitutivity consistency scores (tables are in Appendix C). We observe trends similar to the systematicity results: models trained on larger training sets perform better and synthetic data yields more consistent translations compared to (semi-)natural data. We further observe large variations across synonyms, for which we further detail the performance aggregated across experimental setups in Figure 3b . The three lowest scoring synonyms -\"flautist\", \"aubergine\" and \"ladybug\" -are among the least frequent synonyms (see Appendix C), which stresses the importance of frequency for the model to pick up on synonymy.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 10,
                        "end": 12,
                        "text": "3a",
                        "ref_id": "FIGREF2"
                    },
                    {
                        "start": 437,
                        "end": 439,
                        "text": "3b",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.2.2"
            },
            {
                "text": "In Figure 3b , we show both the regular consistency and the consistency of the synonym translations, illustrating that a substantial part of the inconsistencies are due to varying translations of the context rather than the synonym itself, stressing again the non-local processing of the models.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 10,
                        "end": 12,
                        "text": "3b",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.2.2"
            },
            {
                "text": "In our final test, we focus on exceptions to compositional rules. In natural language, typical exceptions that constitute a challenge for local compositionality are idioms. For instance, the idiom \"raining cats and dogs\" should be treated globally to arrive at its meaning of heavy rainfall. A local approach would yield an overly literal, non-sensical translation (\"het regent katten en honden\"). When a model's translation is too local, we follow Hupkes et al. ( 2020) in saying that it overgeneralises, or, in other words, it applies a general rule to an expression that is an exception to this rule. Overgeneralisation indicates that a language learner has internalised the general rule (e.g. Penke, 2012) .",
                "cite_spans": [
                    {
                        "start": 697,
                        "end": 709,
                        "text": "Penke, 2012)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Global compositionality",
                "sec_num": "4.3"
            },
            {
                "text": "We select 20 English idioms for which an accurate Dutch translation differs from the literal translation from the English MAGPIE corpus (Haagsma et al., 2020) . Because acquisition of idioms is dependent on their frequency in the corpus, we use idioms with at least 200 occurrences in OPUS based on exact matches, for which over 80% of the target translations does not contain a literal translation.",
                "cite_spans": [
                    {
                        "start": 136,
                        "end": 158,
                        "text": "(Haagsma et al., 2020)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.3.1"
            },
            {
                "text": "Test design Per idiom, we extract natural sentences containing the idiom from OPUS. For the synthetic and semi-natural data types, we insert the idiom in 500 samples per idiom per template, by attaching a subordinate clause to a noun -e.g. \"the king that said 'I knew the formula by heart'\". The clauses used can be found in Appendix D, Table 7 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 343,
                        "end": 344,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.3.1"
            },
            {
                "text": "Evaluation Per idiom, we assess how often a model overgeneralises and how often it translates the idiom globally. To do so, we identify keywords that indicate that a translation is translated locally (literal) instead of globally (idiomatic). If the keywords' literal translations are present, the translation is labelled as an overgeneralised translation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.3.1"
            },
            {
                "text": "For instance, for \"by heart\", the presence of \"hart\" (\"heart\") suggests a literal translation. An adequate paraphrase would say \"uit het hoofd\" (\"from the head\"). See Appendix D, Table 7 , for the full list of keywords. We evaluate overgeneralisation for ten intermediate training checkpoints.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 185,
                        "end": 186,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4.3.1"
            },
            {
                "text": "In Figure 4 , we report our results.8 For all evaluation data types and all training set sizes, three phases can be identified. Initially, the translations do not contain the idiom's keyword, not because the idiom's meaning is paraphrased in the translation, but because the translations consist of highfrequency words in the target language only. Afterwards, overgeneralisation peaks: the model emits a very literal translation of the idiom. Finally, the model starts to memorise the idiom's translation. This is in accordance with results from Hupkes et al. (2020) , and earlier results presented in the past tense debate by -among others - Rumelhart and McClelland (1986) .",
                "cite_spans": [
                    {
                        "start": 546,
                        "end": 566,
                        "text": "Hupkes et al. (2020)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 643,
                        "end": 674,
                        "text": "Rumelhart and McClelland (1986)",
                        "ref_id": "BIBREF35"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 10,
                        "end": 11,
                        "text": "4",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.3.2"
            },
            {
                "text": "Although the height of the overgeneralisation peak is similar across evaluation data types and training set sizes, overgeneralisation is more prominent in converged models trained on smaller datasets than it is in models trained on the full corpus.9 In addition to training dataset size, the type of evaluation data used also matters: there is more overgeneralisation for synthetic and seminatural data compared to natural data, stressing the impact of the context in which an idiom is embedded. The extreme case of a context unsupportive of an idiomatic interpretation is a sequence of random words. To evaluate the hypothesis that this yields local translations, we surround the idioms with ten random words. The results (Appendix D, Table 7 ) indicate that, indeed, when the context provides no support at all for a global interpretation, the model provides a local translation for nearly all idioms. Overall, the results of this test provide an interesting contrast with our substitutivity and systematicity results: where in those tests, we saw processing that was less local than we expected, here, the behaviour shown by the models is instead not global enough.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 742,
                        "end": 743,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.3.2"
            },
            {
                "text": "Our systematicity and substitutivity results demonstrate that models are not behaving compositional according to a strict definition of compositionality. However, we ourselves have argued that strict compositionality is not always appropriate to handle natural language. A reasonable question to ask is thus: are the inconsistencies we marked as noncompositional actually incorrect? Annotation setup To address this question, we perform a manual analysis. We annotate 900 inconsistent translation pairs of the systematicity and substitutivity tests to establish whether the inconsistencies are benign or concerning. We consider four different types of changes: 1. cases of rephrasing, where both translations are equally (in)correct; 2. changes reflecting different interpretations of source ambiguities; 3. cases in which one of the two translations contains an error; 4. formatting (mostly punctuation) changes. For substitutivity samples, we also annotate whether the changes are related to the translation of the synonym, where we distinguish cases where i. one of the synonym translations is incorrect; ii. both are incorrect but in a different manner; iii. both are correct but translated differently; iv. one synonym remains untranslated. We annotate all changes observed per pair and report the relative frequency per class. We summarise the results, aggregated over different training set sizes and the three data types, in Figure 5 . For a more elaborate analysis and a breakdown per model and data type, we refer to Appendix F.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 1440,
                        "end": 1441,
                        "text": "5",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Manual analysis",
                "sec_num": "5"
            },
            {
                "text": "In the systematicity test, 40% of the marked inconsistencies reflects wrongfully translated parts in one of the two sentences, whereas 38% contains examples of rephrasing, 16% reflects ambiguities in the source sentences and 6% is caused by formatting differences. For substitutivity, most inconsistencies are similar to the ones observed in systematicity: only 24% involves the synonyms' translations, where one of them being untranslated was the most frequent category. The distribution of these types of inconsistencies differ strongly per training data type. For models trained on less data, inconsistencies are more likely to represent errors, whereas models trained on more data rephrase more often. This result emphasises that for lower-resource settings, being compositional is particularly relevant. Another demonstration of this relevance comes from the observation that although models can emit correct translations for nearly all synonyms,10 they do not always do so, depending on the context. To give a peculiar example: in \"The child admires the king that eats the {doughnut, donut}\", the snack was occasionally translated as \"ezel\" (\"donkey\").",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Robustness and predictability Finally, we would like to stress that while rephrasing often might seem benign rather than concerning from the perspective of emitting adequate translations, its harmlessness still deserves some thought. There is a fine line between rephrasing and mistranslating: whether \"the single largest business establishment\" is referred to as \"de grootste\" (\"the largest\") or \"de enige grootste\" (\"the only largest\") may make or break a translation. Furthermore, if changes are unrelated to the contextual change (e.g. replacing \"soccer\" with \"football\"), this can be undesirable from a robustness and reliability perspective. This point becomes even more pronounced in cases where both translations are correct but have a different meaning. To analyse the extent to which inconsistencies are actually unmotivated, we investigated if we could trace them back to the contextual change, in particular focusing on whether changing synonyms from British to American spelling or vice versa might trigger a change in style or tone. We could not find evidence of such motivations, indicating that even correct cases of rephrasing were not caused by contextual changes that were necessary to take into account.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "In previous work, a variety of artificial tasks have been proposed to evaluate compositional generalisation using non-i.i.d. test sets that are designed to assess a specific characteristic of compositional behaviour. Examples are systematicity (Lake and Baroni, 2018; Bastings et al., 2018; Hupkes et al., 2020) , substitutivity (Mul and Zuidema, 2019; Hupkes et al., 2020) , localism (Hupkes et al., 2020; Saphra and Lopez, 2020) , productivity (Lake and Baroni, 2018) or overgeneralisation (Korrel et al., 2019; Hupkes et al., 2020; Dankers et al., 2021) . Generally, neural models struggle to generalise in such evaluation setups.",
                "cite_spans": [
                    {
                        "start": 244,
                        "end": 267,
                        "text": "(Lake and Baroni, 2018;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 268,
                        "end": 290,
                        "text": "Bastings et al., 2018;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 291,
                        "end": 311,
                        "text": "Hupkes et al., 2020)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 329,
                        "end": 352,
                        "text": "(Mul and Zuidema, 2019;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 353,
                        "end": 373,
                        "text": "Hupkes et al., 2020)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 385,
                        "end": 406,
                        "text": "(Hupkes et al., 2020;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 407,
                        "end": 430,
                        "text": "Saphra and Lopez, 2020)",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 446,
                        "end": 469,
                        "text": "(Lake and Baroni, 2018)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 492,
                        "end": 513,
                        "text": "(Korrel et al., 2019;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 514,
                        "end": 534,
                        "text": "Hupkes et al., 2020;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 535,
                        "end": 556,
                        "text": "Dankers et al., 2021)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "6"
            },
            {
                "text": "There are also studies that consider compositional generalisation on more natural data. Such studies typically focus on either MT (Lake and Baroni, 2018; Raunak et al., 2019; Li et al., 2021) or semantic parsing (Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021) . Most of these studies consider small and highly controlled subsets of natural language.",
                "cite_spans": [
                    {
                        "start": 130,
                        "end": 153,
                        "text": "(Lake and Baroni, 2018;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 154,
                        "end": 174,
                        "text": "Raunak et al., 2019;",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 175,
                        "end": 191,
                        "text": "Li et al., 2021)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 212,
                        "end": 241,
                        "text": "(Finegan-Dollak et al., 2018;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 242,
                        "end": 263,
                        "text": "Keysers et al., 2019;",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 264,
                        "end": 285,
                        "text": "Kim and Linzen, 2020;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 286,
                        "end": 304,
                        "text": "Shaw et al., 2021)",
                        "ref_id": "BIBREF37"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "6"
            },
            {
                "text": "Instead, we focus on models trained on fully natural MT datasets, which we believe to be the setup for compositionality evaluation that does most justice to the complexity of natural language: contrary to semantic parsing, where the outputs are structures created by expert annotators, in translation both inputs and outputs are fully-fledged natural language sentences. To the best of our knowledge, the only attempt to explicitly measure compositional generalisation of NMT models trained on large natural MT corpora is the study presented by Raunak et al. (2019) . They measure productivity -generalisation to longer sentence lengthsof an LSTM-based NMT model trained on a fullsize, natural MT dataset. Other studies using NMT, instead, consider toy datasets generated via templating (Lake and Baroni, 2018) or focus on short sentences excluding more complex constructions that contribute to the complexity of natural language for compositional generalisation, such as polysemous words or metaphors (Li et al., 2021) .",
                "cite_spans": [
                    {
                        "start": 545,
                        "end": 565,
                        "text": "Raunak et al. (2019)",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 787,
                        "end": 810,
                        "text": "(Lake and Baroni, 2018)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 1002,
                        "end": 1019,
                        "text": "(Li et al., 2021)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "6"
            },
            {
                "text": "Whether neural networks can generalise compositionally is often studied using artificial tasks that assume strictly local interpretations of compositionality. We argued that such interpretations exclude large parts of language and that to move towards human-like productive usage of language, tests are needed that assess how compositional models trained on natural data are. 11 We laid out reformulations of three compositional generalisation testssystematicity, substitutivity and overgeneralisation -for NMT models trained on natural corpora, and assessed models trained on different amounts of data. Our work provides an empirical contribution but also highlights vital hurdles to overcome when considering what it means for models of natural language to be compositional. Below, we reflect on these hurdles and our results.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "The proxy-to-meaning problem Compositionality is a property of the mapping between the form and meaning of an expression. Since translation is a meaning-preserving mapping from form in one language to form in another, it is an attractive task to evaluate compositionality: the translation of its sentence can be seen as a proxy to its meaning. However, while expressions are assumed to have only one meaning, translation is a many-to-many mapping: the same sentence can have multiple correct translations. This does not only complicate evaluation -MT systems are typically evaluated with BLEU because accuracy is not a suitable option -it also raises questions about how compositional the desired behaviour of an MT model should be. On the one hand, one could argue that for optimal generalisation, robustness, and accountability, we like models to behave systematically and consistently: we expect the translations of expressions to be independent of unrelated contextual changes that do not affect their meaning (e.g. swapping out a synonym in a nearby sentence). Additionally, model performance could be improved if small changes do not introduce errors in unrelated parts of the translation. On the other hand, non-compositional behaviour is not always incorrect -it is one of the main arguments in our plead to test compositionality 'in the wild' -and we observe that indeed, not all noncompositional changes alter the correctness of the resulting translations. Changing a translation from \"atleet\" (\"athlete\") to \"sporter\" (\"sportsman\") based on an unrelated word somewhat far away may not be (locally) compositional, but is it a problem? And how do we separate such 'harmful' mistakes from helpful ones?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "The locality problem Inextricably linked to the proxy-to-meaning problem is the locality problem. In our tests we see that small, local source changes elicit global changes in translations. For instance, in our systematicity tests, changing one noun in a sentence elicited changes in the translation of a sentence that it was conjoined with. In our substitutivity test, even synonyms that merely differed in spelling (e.g. \"doughnut\" and \"donut\") elicited changes to the remainder of the sentence. This counters the idea of compositionality as a means of productively reusing language: if a phrase's translation depends on (unrelated) context that is not in its direct vicinity, this suggests that more evidence is required to acquire the translation of this phrase.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "Tests involving synthetic data present the models with sentences in which maximally local behaviour is possible, and we argue that it is, therefore, also desirable. Our experiments show that even in such setups, models do not translate in a local fashion: with varying degrees of correctness, they frequently change their translation when we slightly adapt the input. On the one hand, this well-known volatility (see also Fadaee and Monz, 2020 ) might be essential for coping with ambiguities for which meanings are context-dependent. On the other hand, our manual analysis shows that the observed noncompositional behaviour does not reflect the incorporation of necessary contextual information and that oftentimes it is even altering the correctness of the translations. Furthermore, this erratic behaviour highlights a lack of default reasoning, which can, in some cases, be problematic or even harmful, especially if faithfulness (Parthasarathi et al., 2021) or consistency is important.",
                "cite_spans": [
                    {
                        "start": 422,
                        "end": 443,
                        "text": "Fadaee and Monz, 2020",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 934,
                        "end": 962,
                        "text": "(Parthasarathi et al., 2021)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "In linguistics, it has been discussed how to extend the syntax and semantics such that 'problem cases' can be a part of a compositional language (Westerst\u00e5hl, 2002; Pagin and Westerst\u00e5hl, 2010) . In such formalisations, global information is used to disambiguate the problem cases, while other parts of the language are still treated locally. In our models, global behaviour appears in situations where a local treatment would be perfectly suitable and where there is no clear evidence for ambiguity. We follow Baggio (2021) in suggesting that we should learn from strategies employed by humans, who can assign compositional interpretations to expressions but can for some inputs also derive noncompositional meanings. For human-like linguistic generalisation, it is vital to investigate how models can represent both these types of processing, providing a locally compositional treatment when possible and deviating from that when needed.",
                "cite_spans": [
                    {
                        "start": 145,
                        "end": 164,
                        "text": "(Westerst\u00e5hl, 2002;",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 165,
                        "end": 193,
                        "text": "Pagin and Westerst\u00e5hl, 2010)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 511,
                        "end": 524,
                        "text": "Baggio (2021)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "In conclusion, with this work, we contribute to the question of how compositional models trained on natural data are, and we argue that MT is a suitable and relevant testing ground to ask this question. Focusing on the balance between local and global forms of compositionality, we formulate three different compositionality tests and discuss the issues and considerations that come up when considering compositionality in the context of natural data. Our tests indicate that models show both local and global processing, but not necessarily for the right samples. Furthermore, they underscore the difficulty of separating helpful and harmful types of non-compositionality, stressing the need to rethink the evaluation of compositionality using natural language, where composing meaning is not as straightforward as doing the math. The Npeople Vtransitive the N sl people . E.g. The poet criticises the king .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": null
            },
            {
                "text": "The Npeople Adv Vtransitive the N sl people . E.g. The victim carefully observes the queen .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "2",
                "sec_num": null
            },
            {
                "text": "The Npeople P the N sl vehicle Vtransitive the N sl people . E.g. The athlete near the bike observes the leader . 4",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "3",
                "sec_num": null
            },
            {
                "text": "The Npeople and the Npeople V pl transitive the N sl people . E.g. The poet and the child understand the mayor . 5",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "3",
                "sec_num": null
            },
            {
                "text": "The N sl quantity of N pl people P the N sl vehicle V sl transitive the N sl people . E.g. The group of friends beside the bike forgets the queen .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "3",
                "sec_num": null
            },
            {
                "text": "The Npeople Vtransitive that the N pl people V pl intransitive.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6",
                "sec_num": null
            },
            {
                "text": "E.g. The farmer sees that the lawyers cry . 7",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6",
                "sec_num": null
            },
            {
                "text": "The Npeople Adv Vtransitive that the N pl people V pl intransitive . E.g. The mother probably thinks that the fathers scream . 8",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6",
                "sec_num": null
            },
            {
                "text": "The Npeople Vtransitive that the N pl people V pl intransitive Adv . E.g. The mother thinks that the fathers scream carefully . 9",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6",
                "sec_num": null
            },
            {
                "text": "The Npeople that Vintransitive Vtransitive the N sl people . E.g. The poets that sleep understand the queen . 10 The Npeople that Vtransitive Pro V sl transitive the N sl people . E.g. The mother that criticises him recognises the queen .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "6",
                "sec_num": null
            },
            {
                "text": "Table 3 : Synthetic sentence templates similar to Lakretz et al. (2019) , along with their identifiers (n). . 86 .74 .85 .87 .75 .89 .85 .85 .70 .68 .92 .73 .90 .91 .84 .88 .85 .82 .77 .74 .66 .63 .65 .70 .64 .69 .63 .63 .60 .58 .91 .82 .88 .88 .86 .95 .90 .91 .84 .79 .75 .54 .72 .66 .73 .88 .74 .81 .66 .55 .73 .75 .75 .80 .75 .73 .66 .68 .64 .64 .50 .50 .51 .58 .52 .43 .35 .31 .28 .29 .67 .74 .65 .64 .63 .64 .62 .66 .63 .66 .39 .49 .35 .35 .34 .37 .33 .38 .34 .38 (b) Per template then use the list of all words resulting from this protocol -which we manually checked -to find synonym translations in the model output.",
                "cite_spans": [
                    {
                        "start": 50,
                        "end": 71,
                        "text": "Lakretz et al. (2019)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 110,
                        "end": 472,
                        "text": "86 .74 .85 .87 .75 .89 .85 .85 .70 .68 .92 .73 .90 .91 .84 .88 .85 .82 .77 .74 .66 .63 .65 .70 .64 .69 .63 .63 .60 .58 .91 .82 .88 .88 .86 .95 .90 .91 .84 .79 .75 .54 .72 .66 .73 .88 .74 .81 .66 .55 .73 .75 .75 .80 .75 .73 .66 .68 .64 .64 .50 .50 .51 .58 .52 .43 .35 .31 .28 .29 .67 .74 .65 .64 .63 .64 .62 .66 .63 .66 .39 .49 .35 .35 .34 .37 .33 .38 .34 .38 (b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "6",
                "sec_num": null
            },
            {
                "text": "In the main paper, Figures 3a and 3b provided the consistency scores for the substitutivity tests. Here, .54 .87 .74 .82 .10 .92 .78 .64 .79 .55 .25 .40 .64 .73 .68 .81 .27 .85 .48 .88 syn. con. 1.0 1.0 .87 1.0 .10 1.0 1.0 .80 .95 1.0 .38 .48 .90 1.0 .75 1.0 .40 .99 .53 1.0 semi-natural con.",
                "cite_spans": [
                    {
                        "start": 105,
                        "end": 180,
                        "text": ".54 .87 .74 .82 .10 .92 .78 .64 .79 .55 .25 .40 .64 .73 .68 .81 .27 .85 .48",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 27,
                        "end": 29,
                        "text": "3a",
                        "ref_id": "FIGREF2"
                    },
                    {
                        "start": 34,
                        "end": 36,
                        "text": "3b",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": ". 43 .59 .58 .54 .08 .85 .52 .55 .56 .42 .24 .31 .33 .73 .66 .71 .20 .62 .43 .75 syn. con. .99 .99 .83 1.0 .09 1.0 .98 .72 .90 .98 .40 .50 .77 1.0 .90 1.0 .38 .95 .58 .99 natural con. .50 .52 .53 .56 .09 .75 .50 .60 .47 .57 .23 .70 .29 .64 .55 .62 .17 .59 .61 .58 syn. con. .89 .85 .73 .91 .11 .87 .87 .82 .88 .86 .32 .92 .75 .71 .79 .81 .27 .82 .81 .80 (b) ",
                "cite_spans": [
                    {
                        "start": 2,
                        "end": 357,
                        "text": "43 .59 .58 .54 .08 .85 .52 .55 .56 .42 .24 .31 .33 .73 .66 .71 .20 .62 .43 .75 syn. con. .99 .99 .83 1.0 .09 1.0 .98 .72 .90 .98 .40 .50 .77 1.0 .90 1.0 .38 .95 .58 .99 natural con. .50 .52 .53 .56 .09 .75 .50 .60 .47 .57 .23 .70 .29 .64 .55 .62 .17 .59 .61 .58 syn. con. .89 .85 .73 .91 .11 .87 .87 .82 .88 .86 .32 .92 .75 .71 .79 .81 .27 .82 .81 .80 (b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Idioms employed Table 7 provides more information on the idioms used in our global compositionality test. In the first column, we list all idioms we used, along with the keywords that we used to determine if their translation is local or not. To extract the natural data, we retrieved exact matches with OPUS source sentences. The idioms' keywords are mostly nouns that either translate into a different word in an accurate paraphrased translation in Dutch (e.g. \"across the board\" would be \"over de hele linie\"), or should disappear in the translation (e.g. \"do the right thing\" typically translates into \"het juiste doen\" in the corpus).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 22,
                        "end": 23,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Appendix D Global compositionality",
                "sec_num": null
            },
            {
                "text": "In the second column of Table 7 , we list the subordinate clauses that we used to include idioms in the synthetic and semi-natural data. The clauses themselves are drawn from source sentences in OPUS. To incorporate them in synthetic and semi-natural sentences, we include them as a relative clause behind nouns representing a human, by attaching \"that said '[idiom]\"'. For instance: \"The poet criticises the king that said 'Have you gone out of your mind'.\"",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 30,
                        "end": 31,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Appendix D Global compositionality",
                "sec_num": null
            },
            {
                "text": "In the third column of Table 7 , we show local translations of the idioms, elicited from the model by embedding the idiom in a string of ten random nouns. Even \"out of the blue\", which is rarely overgeneralised when presented in synthetic, semi-natural or natural contexts, is locally translated. This indicates that the idiom is not stored as one lexical unit per se but that it is only translated globally in specific contexts.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 29,
                        "end": 30,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Appendix D Global compositionality",
                "sec_num": null
            },
            {
                "text": "In the main paper, in Figure 4 , we visualised how overgeneralisation changes over the course of training, averaged over idioms. In Table 8 , we detail the maximum overgeneralisation observed per idiom.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 29,
                        "end": 30,
                        "text": "4",
                        "ref_id": "FIGREF3"
                    },
                    {
                        "start": 138,
                        "end": 139,
                        "text": "8",
                        "ref_id": "TABREF7"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "once in a while that said \" I will play it once in a while \" eens in een tijdje do the right thing that said \" Just do the right thing \" doen het juiste ding out of your mind that said \" Have you gone out of your mind \" uit je hoofd state of the art that said \" This is a state of the art, official facility \" stand van de kunst from scratch that said \" We are cooking from scratch every day \" van kras take stock that said \" Take stock of the lessons to be drawn \" nemen voorraad across the board that said \" I got red lights all across the board \" aan boord in the final analysis that said \" In the final analysis, this is what matters \" in de laatste analyse out of the blue that said \" It just came out of the blue \" uit het blauwe in tandem that said \" We will work with them in tandem \" in tandem by heart that said \" I knew the formula by heart \" door hart come to terms with that said \" I have come to terms with my evil past \" komen overeen met by the same token that said \" By the same token I will oppose what is evil \" bij dezelfde token at your fingertips that said \" The answer is right at your fingertips \" binnen handbereik look the other way that said \" We cannot look the other way either \" kijken de andere manier follow suit that said \" And many others follow suit \" volgen pak keep tabs on that said \" I keep tabs on you \" houden tabs in the short run that said \" In the short run it clearly must be \" in de korte lopen by dint of that said \" We are part of it by dint of our commitment \" door de int set eyes on that said \" I wish I had never set eyes on him \" set ogen op Table 7 : Idioms used in the overgeneralisation test. The words that are indicative of a local translation are underlined, we check for their presence to label a translation as an overgeneralisation. The listed subordinate clauses are used to insert the idioms into synthetic and semi-natural templates. The local translation indicated is the translation given by the model when the idiom is embedded in a string of ten random words. .80 .51 .80 .97 .84 .31 .75 .96 .92 .82 .88 .14 .74 .60 1.0 .40 .96 .29 .23 .87 medium .80 .50 .82 .96 .84 .32 .71 .94 .92 .68 .90 .22 .74 .63 .99 .39 .61 .33 .29 .84 full .79 .39 .83 .95 .90 .36 .83 .98 .95 .89 .90 .11 .65 .55 1.0 .65 .56 .19 .27 .76 Preprocessing We tokenise the data using the tokenisation script13 from the SMT library Moses.14 Following the number of subwords suggested by Tiedemann (2020), we generate a subword vocabulary applying 60k BPE merge-operations. To do so, we use the learn bpe.py script provided in the SUBWORD NMT15 repository hosted by Rico Sennrich.",
                "cite_spans": [
                    {
                        "start": 2029,
                        "end": 2280,
                        "text": ".80 .51 .80 .97 .84 .31 .75 .96 .92 .82 .88 .14 .74 .60 1.0 .40 .96 .29 .23 .87 medium .80 .50 .82 .96 .84 .32 .71 .94 .92 .68 .90 .22 .74 .63 .99 .39 .61 .33 .29 .84 full .79 .39 .83 .95 .90 .36 .83 .98 .95 .89 .90 .11 .65 .55 1.0 .65 .56 .19 .27 .76",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 1601,
                        "end": 1602,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Subordinate clause Local translation",
                "sec_num": null
            },
            {
                "text": "Different corpora We train models on three different sizes of corpora: SMALL, MEDIUM and FULL.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subordinate clause Local translation",
                "sec_num": null
            },
            {
                "text": "To generate these corpora, we first shuffle the OPUS training data using the bash function shuffle. To generate the SMALL and MEDIUM corpora, we take the first 8582811 and 1072851 sentences of this shuffled corpus, which corresponds to 1 8 th and 1 64 th of the full training corpus, respectively. For each setting, we train models with seeds {1, 2, 3, 4, 5}.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subordinate clause Local translation",
                "sec_num": null
            },
            {
                "text": "Test and validation data Initially, we aimed to evaluate our models using the commonly used MT test sets OPUS-100 16 and the test partition of the TED talk corpus.17 However, it turned out that both these test sets were almost fully contained in our training corpus. We, therefore, adopted the newer FLORES-101 corpus (Goyal et al., 2021) , of which we used both the 'dev' and the 'devtest' set. The data can be downloaded from https://dl.fbaipublicfiles.com/flores101/dataset/flores101 dataset.tar.gz. To compute BLEU scores, we tokenised the data with the Moses tokenisation script mentioned above, and then used the commandline script fairseq-generate to compute scores.",
                "cite_spans": [
                    {
                        "start": 318,
                        "end": 338,
                        "text": "(Goyal et al., 2021)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subordinate clause Local translation",
                "sec_num": null
            },
            {
                "text": "We furthermore use several evaluation sets to assess the compositional abilities of our trained models. The data for these tests, as well as scripts to run them and plot their results, can be found in the following repository: https://github.com/i-machine-think/compositionality paradox mt.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subordinate clause Local translation",
                "sec_num": null
            },
            {
                "text": "As reported in the main text, we focus on English-Dutch translation, and all our models are Transformerbase models, as implemented in Fairseq (Ott et al., 2019) . 18 Both the encoder and the decoder of this model have an embedding dimension of 512, 6 layers, 8 attention heads and a feed-forward layer dimension of 2048. With our vocabulary, the models have a total of around 80M trainable parameters.",
                "cite_spans": [
                    {
                        "start": 142,
                        "end": 160,
                        "text": "(Ott et al., 2019)",
                        "ref_id": "BIBREF25"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "E.2 Architecture and training",
                "sec_num": null
            },
            {
                "text": "To train our models, we follow the training procedure suggested by Ott et al. (2018) , which can be found at https://github.com/pytorch/fairseq/tree/master/examples/scaling nmt. To summarise, we share all embeddings between the encoder and the decoder, use Adam as optimiser with \u03b2-values (0.9, 0.98), starting from an initial warmup learning rate of 1e-07 for 4000 warmup updates and a learning rate of 0.0005 afterwards, using inverse square root as the learning rate scheduler. We use a clip-norm of 0.0, dropout of 0.3, weight-decay of 0.0001, label-smoothing of 0.1. The maximum number of tokens in a batch is 3584, we simulate larger batches by increasing the update frequency to 8. To determine early stopping, we use a patience of 10 (i.e. we stop training if a model does not improve on the dev set anymore for 10 epochs, and take the best checkpoint at that point). Any other hyperparameters involved follow the Fairseq default. We provide the BLEU scores per model seed in Table 9 .",
                "cite_spans": [
                    {
                        "start": 67,
                        "end": 84,
                        "text": "Ott et al. (2018)",
                        "ref_id": "BIBREF26"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 990,
                        "end": 991,
                        "text": "9",
                        "ref_id": "TABREF8"
                    }
                ],
                "eq_spans": [],
                "section": "E.2 Architecture and training",
                "sec_num": null
            },
            {
                "text": "All experiments were ran using Tesla V100 GPUs on an internal SLURM-based cluster. Training a transformer-base model on our small, medium and full dataset takes on average 3.5, 17 and 113 minutes per epoch, respectively (numbers are rounded) on 32 GPUs. This makes the total training time for these models, which are trained for around 160, 60 and 30 epochs, 10, 17 and 56 hours, respectively (again, spread over 32 GPUs).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "E.3 Compute",
                "sec_num": null
            },
            {
                "text": "Our quantitative tests provide information on when a model behaves locally and when globally in automated form but they do not consider whether that behaviour is incorrect or not. More simply put, we do not know whether the changes that we observe are actually resulting in incorrect translations. We complement these scores with an elaborate manual analysis, which provides more insight into the nature of the non-compositional behaviour we registered.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Appendix F Manual analysis",
                "sec_num": null
            },
            {
                "text": "Data sampling We randomly sample 900 examples for substitutivity (100 for each {model}\u00d7{test data type} tuple) and 900 examples for systematicity (50 for each {model}\u00d7{test data type}\u00d7{S 1 , S 3 } tuple), randomly distributed over templates. In all cases, we sample sentences randomly from the five seeds that we trained, and from all templates. For substitutivity, we sample five examples for each synonym for every (model, test data) pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.1 Setup",
                "sec_num": null
            },
            {
                "text": "Annotation procedure For each of these samples, we annotate how they differ, where we distinguish between four general categories: i. Rephrasing: part of the sentence is rephrased (but both phrases are equally (in)correct); ii. Source ambiguities: there is an ambiguity in the source sentence, and the model switches its interpretation; iii. Errors: one of the translations contains an error that the other one does not; iv. Formatting: minor formatting changes, consisting mostly of insertions/deletions of punctuation. For the substitutivity data, we separately annotate changes that are related to the translation of the synonym, where we distinguish cases in which both synonyms are correctly or incorrectly translated from cases in which one of the translations is correct. We annotate all changes observed in a sample -one sentence may thus contain annotations for multiple changes -and report the relative frequency of each class of errors. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.1 Setup",
                "sec_num": null
            },
            {
                "text": "We provide a summary of the results in Figure 6 for systematicity and Figure 7 for substitutivity. As a general trend, the results reflect that in models trained on smaller datasets, more mistakes are actually errors, rather than multiple correct alternatives. In the systematicity test, 59% of the inconsistencies for the models trained on the smallest dataset are erroneous changes, versus 34% and 27% in the models trained on the medium and largest dataset, when we average the percentages over the different subsets annotated. For substitutivity, the percentage of erroneous changes unrelated to the synonyms comprises 46%, 18% and 22% for the smallest, medium and full dataset, respectively. On top of that, there were inconsistencies related to the synonyms, that represented 26%, 26% and 21% for the three dataset sizes, respectively. While this is expected, to some extent, it still constitutes a problem: for models trained on smaller amounts of data, being able to translate in a compositional manner is particularly relevant. Below, we further elaborate on the types of inconsistencies encountered per annotation category, including some examples. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 46,
                        "end": 47,
                        "text": "6",
                        "ref_id": "FIGREF7"
                    },
                    {
                        "start": 77,
                        "end": 78,
                        "text": "7",
                        "ref_id": "FIGREF8"
                    }
                ],
                "eq_spans": [],
                "section": "F.2 Results",
                "sec_num": null
            },
            {
                "text": "A large portion of the inconsistencies concerns pairs where one translation can be considered a rephrased version of the other translation. A common cause of this is a reordering of words that does not impact the grammaticality or meaning of the Dutch sentence -e.g. in sentences with adverbs (\"heeft de burgemeester zeker in de gaten\" vs \"heeft zeker de burgemeester in de gaten\") or relative clauses with direct objects (\"die genieten van de vakantie\" vs \"die van de vakantie genieten\"). We could not trace these reorderings back to the specific change made in the systematicity or substitutivity tests. Consider, for instance, Example (1), where the reordering happens as a consequence of changing the word \"king\" to \"father\". Note also that while these translations both contain an error (\"neemt . . . in de gaten\"), this is not marked as an inconsistency, because it is shared between the translations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.1 Rephrasing",
                "sec_num": null
            },
            {
                "text": "(1) a. EN: The aunts criticise the {king, father}, and the man definitely observes the mayor. b. NL: (. . . ) en de man neemt zeker de burgemeester in de gaten. c. NL: (. . . ) en de man neemt de burgemeester zeker in de gaten.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.1 Rephrasing",
                "sec_num": null
            },
            {
                "text": "Another commonly occurring case of rephrasing is one where the two translations include terms that are (nearly) synonymous terms in Dutch. Some examples are the translation of athlete (\"sporter\" vs \"atleet\"), wish (\"wensen\" vs \"willen\") and observe (\"observeren\" vs \"waarnemen\"). Some of them can appear in the same context but for others the two words would typically appear in different types of texts. For instance, the word \"dokter\" is used in more informal contexts than the word \"arts\" (both translations of \"doctor\"). Again, we could not identify an interpretable pattern for when the model emits one instead of the other -they were not understandably related to the modifications we made to the inputs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.1 Rephrasing",
                "sec_num": null
            },
            {
                "text": "An intriguing category that we had not anticipated were cases in which the source sentence contained ambiguities, such as polysemous words (e.g. \"director\" translated to \"directeur\", referring to the director of a company, and \"regisseur\", indicating the director of a movie). Other ambiguities encountered were scope ambiguities, that were particularly prominent for the systematicity test. In that test, we concatenate two sentences, and the ambiguity was often related to the verb in the first sentence -e.g. in Example (2):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "(2) a. EN: The friend wishes that the {lawyers, directors} scream, and the victims (. . . )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "While we intended this to be a conjunction of two independent sentences, there is also a reading where \"wishes\" takes scope over the entire second conjunct. In Dutch, those two cases are distinguishable because they trigger a different word order in the embedded clause (SOV), which is not grammatical for main clauses. Such scope changes often lead to very questionable interpretations of the English sentence, as is the case for Example (3):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "(3) a. EN: The victims want that the {doctors, mayors} run, and the victims read an article about the case of a procedure which includes a repayment plan. b. EN: The farmers think that the {butchers, mothers} laugh, and an error can only be seen whenever we have a basic plan that is constantly compared to our real actions. c. EN: The women wish that the {painters, victims} walk consciously, and every 2CV or Dyane can basically be used as a donor.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "Interestingly, the models sometimes also changed the order in the relative clause when a scope change was not possible, for instance when the second conjunct was a question, or the verb in the first sentence did not allow to take scope over the second conjunct without the presence of the word \"that\". See Example (4). We underline the incorrect part of the translation, here and in erroneous examples that follow.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "(4) a. EN: The victim observes the {leader, king}, and the fathers carefully avoid the president. b. NL: Het slachtoffer observeert de leider en de vaders de president zorgvuldig vermijden. c. NL: Het slachtoffer observeert de koning en de vaders vermijden voorzichtig de president.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "These examples indicate that the interpretation of scope change might not be applicable here and that instead, the model is applying some heuristic where particular words trigger a relative clause order.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.2 Source ambiguities",
                "sec_num": null
            },
            {
                "text": "In the category 'target errors', some of the errors can be easily traced to individual words, whereas others indicate overall misinterpretations of the input.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "Single word errors Errors that consist of single words are caused by words that are either missing, wrongly translated or untranslated. Changes due to missing words can be very minor but nevertheless render one of the sentences ungrammatical (e.g. \"De tante achter de truck bewonderde de directeur\", correct, vs \"De tante achter de truck bewonderde directeur\", incorrect), or yield grammatical sentences that have a slightly different meaning (e.g. \"de arts die yoghurt eet\" vs \"de arts die de yoghurt eet\").",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "Missing words can also render translations both ungrammatical and semantically incorrect, which occured mostly in case of missing nouns or verbs (e.g. \"de bakker die ons herkent, merkt de koning op\", correct, vs \"de bakker die ons de koning herkent\", incorrect). We also encoutered pairs where one translation contained untranslated source words. This happened with some of the words in our synthetic templates (e.g. \"ooms\"/\"uncles\", \"butchers\"/\"slagers\") but also with words from the natural sentences (e.g. \"extrusion\"/\"extrusie\", \"soils\"/\"bodem\"). These cases mark examples where local processing would have been helpful to the model: as evidenced by the alternative translation in the pair, the model does have access to the correct translation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "Thirdly, we observed cases of mistranslated words, where words unrelated to the change locus received a wrong translation in one of the two sentences but a correct one in the other, for example: \"poets\" being translated as \"dichters\" (correct) vs \"de potten\" (incorrect), \"general\" as \"generaal\" (correct) vs \"wandeling\" (incorrect), or \"productform\" as \"productvorm\" (correct) vs \"productformulier\" (incorrect).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "Multi-word errors Other types of errors are less easily located to individual words but indicate an overall misinterpretation of the input, such as the change in the tense as displayed in Example (5), and the change in agreement displayed in Example (6). In these particular cases, the source of confusion is explainable: in the first case, the model is combining a present tense verb with a word-order that does not support that, even though such a word order does exist (\"in het najaar van 2005 . . . en komen er al snel een paar . . . \"). In the second case, \"begrijpt\" should agree with \"schilder\" but instead agrees with the word \"doctor\", much earlier in the sentence. In both of these cases, a more locally compositional approach to translating would have yielded correct translations. (6) a. EN: The doctors that laugh admire the {president, baker}, the painter that admires her understands the king.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "b. NL: (. . . ) de schilder die haar bewondert, begrijpen de koning. c. NL: (. . . ) de schilder die haar bewondert begrijpt de koning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "Finally, we would like to point out an error type that relates to the semantic role assigned to agents, and brings about a lot of other changes in the process. For instance, in Example (7), \"the fathers\" is removed from the main clause and moved into the relative clause, leaving the main clause without its direct object.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "(7) a. EN: The group of painters behind the truck forgets the {president, friend} and an article about the previous EESC Opinion on alcohol related harm, which looked at f, is read by the fathers b. NL: (. . . ) en een artikel over het eerdere advies van het EESC over alcoholgerelateerde schade, die door de vaders wordt onderzocht, wordt gelezen. c. NL: (. . . ) en een artikel over het eerdere advies van het EESC over alcoholgerelateerde schade, die naar f uitkeek, wordt door de vaders gelezen.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.3 Target errors",
                "sec_num": null
            },
            {
                "text": "We marked inconsistencies as formatting changes if they were related to punctuation, capitalisation, hyphenation or differences in usage of spaces. In most cases, those cases were caused by comma's: in one translation, a relative clause or two conjuncts were separated by a comma, whereas the other one was not. In the cases that were caused by spaces (\"tumormassa\" vs \"tumor massa\"), there is a slight difference in correctness: in Dutch, compound nouns are not separated by spaces. Given how minor these mistakes are, we did not mark them as errors. Example (6) above provides an example for inconsistent usage of commas. Formatting changes are far from the most frequent but they do become more prominent in models trained on larger training corpora.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.4 Formatting",
                "sec_num": null
            },
            {
                "text": "The synonym errors are subdivided into cases where synonyms are simply translated differently (we observed this mostly for the models with larger training set sizes), cases where both translations were incorrect, cases in which only one translation is wrong, and cases in which one synonym was not translated but directly copied from the source. Sometimes, the changes were quite peculiar, to give some examples from our natural corpus:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.5 Inconsistentcies in synonym translations",
                "sec_num": null
            },
            {
                "text": "(8) a. EN: The child admires the king that eats the {doughnut, donut}. b. NL: Het kind bewondert de koning die de donut eet. c. NL: Het kind bewondert de koning die de ezel eet.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.5 Inconsistentcies in synonym translations",
                "sec_num": null
            },
            {
                "text": "(9) a. EN: -Yeah, a barbecue sauce {moustache, mustache} contest. b. NL: -Ja, een barbecue [missing 'sauce'] met snor. c. NL: -Ja, een barbeceu saus snor wedstrijd.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.5 Inconsistentcies in synonym translations",
                "sec_num": null
            },
            {
                "text": "How often each of these errors occur depends on the synonym. Where some synonyms are more prone to being untranslated (like \"ladybird\" and \"flautist\"), some simply received many different correct translations (like \"shopping trolley\") yet others received errors very specific to the synonym (like \"eggplant\" being translated as \"egg\"+\"plant\", an interesting case because it reflects processing that is too local). It should be noted that for all synonyms -apart from the model with the small training dataset that cannot translate \"flautist\" and \"ladybug\" -we have observed correct translations, indicating that the models did in fact acquire their meaning. Further, it should be noted that while our substitutivity experiment provides insight into how the model copes with individual synonyms, the majority of the inconsistencies observed were still common target errors, rephrasings, changes in formatting or the result of source-side ambiguities. It is vital here to stress that the types of rephrasings, however, did not appear related to the writing style of the sentence. For instance, considering that the synonym changes were related to British and American spelling, and occassionally changed the tone of the sentence (e.g. \"aeroplane\" could be considered more archaic compared to \"airplane\"), one could anticipate changes in word choice in Dutch reflecting this change of style. However, the inconsistencies were virtually indistinguishable from those annotated for systematicity.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F.2.5 Inconsistentcies in synonym translations",
                "sec_num": null
            },
            {
                "text": "The data and code are available at https://github. com/i-machine-think/compositionality paradox mt. We present details concerning reproducibility in Appendix E.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Apart from Raunak et al. (2019), work on compositionality and 'natural' language considers highly structured subsets of language (e.g.Kim and Linzen, 2020;Keysers et al., 2019).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "E.g. SCAN's inputs are instructions (\"walk twice\") with executions as outputs (\"walk walk\")(Lake and Baroni, 2018).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "This straightforwardly extends to translation, by replacing meaning with translation (Rosetta, 1994).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Visit the Tatoeba challenge for the OPUS training data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "All training details are listed in Appendix E.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In our manual analysis ( \u00a75), however, we did observe a slightly different distribution of changes between these setups.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that epochs consist of different numbers of samples: 1M, 8.6M and 69M for small, medium and full. Appendix D further details numerical results per idiom.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Convergence is based on BLEU scores for validation data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Apart from the model with the small training dataset that cannot translate \"flautist\" and \"ladybug\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Dupoux (2018) makes a similar point for models of language acquisition, providing several concrete examples where using less than fully complex data proved problematic.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/andreasvc/disco-dop",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/moses-smt/mosesdecoder",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/rsennrich/subword-nmt/blob/master/subword nmt/learn bpe.py",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-nl/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/neulab/word-embeddings-for-nmt",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We used the implementation as it was on May 12, 2021: https://github.com/pytorch/fairseq/blob/ d151f2787240cca4e3c7e47640e647f8ae028c37/fairseq/models/transformer.py",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We thank Sebastian Riedel, Douwe Kiela, Thomas Wolf, Khalil Sima'an, Marzieh Fadaee, Marco Baroni, Brenden Lake and Adina Williams for providing feedback on this draft and our work in several different stages of it. We thank Michiel van der Meer for contributing to the initial experiments that led to this paper. A special thanks goes to Angela Fan, who assisted us at several points to get the ins and outs of training large MT models and double-checked several steps of our pipeline and to our ARR reviewers, who provided amazingly high quality feedback. VD is supported by the UKRI Centre for Doctoral Training in Natural Language Processing, funded by the UKRI (grant EP/S022481/1) and the University of Edinburgh.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgements",
                "sec_num": null
            },
            {
                "text": "The semi-natural data that we use in our test sets is generated with the library DiscoDOP, 12 developed for data-oriented parsing (Van Cranenburgh et al., 2016) . We generate the data with the following seven step process:Step 1. Sample 100k English OPUS sentences.Step 2. Generate a treebank using the disco-dop library and the discodop parser en ptb command. The library was developed for discontinuous data-oriented parsing. Use the library's --fmt bracket to turn off discontinuous parsing.Step 3. Compute tree fragments from the resulting treebank (discodop fragments). These tree fragments are the building blocks of a Tree-Substitution Grammar.Step 4. We assume the most frequent fragments to be common syntactic structures in English. To construct complex test sentences, we collect the 100 most frequent fragments containing at least 15 non-terminal nodes for NPs and VPs.Step 5. Selection of three VP and five NP fragments to be used in our final semi-natural templates. These structures are selected through qualitative analysis for their diversity.Step 6. Extract sentences matching the eight fragments (discodop treesearch).Step 7. Create semi-natural sentences by varying one lexical item and varying the matching NPs and VPs retrieved in Step 6.In Table 2 , we provide examples for each of the ten templates used, along with the internal structure of the complex NP or VP that is varied in the template. In Table 3 , we provide some additional examples for our ten synthetic templates. E.g. Did the lawyers hear about a qualification procedure to examine the suitability of the applicants ?Table 2 : Semi-natural data templates along with their identifiers (n). The syntactic structures for noun and verb phrases in purple are instantiated with data from the OPUS collection. Generated data from every template contains varying sentence structures and varying tokens but the predefined tokens in black remain the same.",
                "cite_spans": [
                    {
                        "start": 130,
                        "end": 160,
                        "text": "(Van Cranenburgh et al., 2016)",
                        "ref_id": "BIBREF42"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 1269,
                        "end": 1270,
                        "text": "2",
                        "ref_id": null
                    },
                    {
                        "start": 1428,
                        "end": 1429,
                        "text": "3",
                        "ref_id": null
                    },
                    {
                        "start": 1611,
                        "end": 1612,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Appendix A Semi-natural templates",
                "sec_num": null
            },
            {
                "text": "Synonyms employed In Table 5 , we provide some information about the synonymous word pairs used in the substitutivity test, including their frequency in OPUS and their most common Dutch translation.The last column of the table contains the subordinate clauses that we used to include the synonyms in the synthetic and semi-natural data. We include them as a relative clause behind nouns representing a human, such as \"The poet criticises the king that eats the doughnut\".Detecting synonym translations To find the span of text in the translation which is the translation of the synonym, we apply a relatively simple heuristic. We generate a number of short sentences such as \"This is the NOUN\", feed those to all our trained models, and extract the top-5 answers in the beam. We",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 27,
                        "end": 28,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Appendix C Substitutivity",
                "sec_num": null
            },
            {
                "text": "Training data Our training data consists of the English-Dutch subset of the MT corpus OPUS (Tiedemann and Thottingal, 2020), provided by Tiedemann (2020) . This data contains in total 69M source-target pairs. The data can be found on https://github.com/Helsinki-NLP/Tatoeba-Challenge/blob/master/data/ README-v2020-07-28.md.",
                "cite_spans": [
                    {
                        "start": 137,
                        "end": 153,
                        "text": "Tiedemann (2020)",
                        "ref_id": "BIBREF40"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Appendix E Reproducibility details E.1 Data",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Compositionality in a parallel architecture for language processing",
                "authors": [
                    {
                        "first": "Giosu\u00e8",
                        "middle": [],
                        "last": "Baggio",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Cognitive Science",
                "volume": "45",
                "issue": "5",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.1111/cogs.12949"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Giosu\u00e8 Baggio. 2021. Compositionality in a parallel architecture for language processing. Cognitive Sci- ence, 45(5):e12949.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Jump to better conclusions: SCAN both left and right",
                "authors": [
                    {
                        "first": "Jasmijn",
                        "middle": [],
                        "last": "Bastings",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Baroni",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Douwe",
                        "middle": [],
                        "last": "Kiela",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Workshop: Analyzing and Interpreting Neural Networks for NLP, Black-boxNLP@EMNLP 2018",
                "volume": "1",
                "issue": "",
                "pages": "47--55",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/w18-5407"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jasmijn Bastings, Marco Baroni, Jason Weston, Kyunghyun Cho, and Douwe Kiela. 2018. Jump to better conclusions: SCAN both left and right. In Proceedings of the Workshop: Analyzing and Interpreting Neural Networks for NLP, Black- boxNLP@EMNLP 2018, Brussels, Belgium, Novem- ber 1, 2018, pages 47-55. Association for Computa- tional Linguistics.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Can transformers jump around right in natural language? assessing performance transfer from scan",
                "authors": [
                    {
                        "first": "Rahma",
                        "middle": [],
                        "last": "Chaabouni",
                        "suffix": ""
                    },
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Dess\u00ec",
                        "suffix": ""
                    },
                    {
                        "first": "Eugene",
                        "middle": [],
                        "last": "Kharitonov",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
                "volume": "",
                "issue": "",
                "pages": "136--148",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rahma Chaabouni, Roberto Dess\u00ec, and Eugene Kharitonov. 2021. Can transformers jump around right in natural language? assessing performance transfer from scan. In Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpret- ing Neural Networks for NLP, pages 136-148.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Generalising to German plural noun classes, from the perspective of a recurrent neural network",
                "authors": [
                    {
                        "first": "Verna",
                        "middle": [],
                        "last": "Dankers",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Langedijk",
                        "suffix": ""
                    },
                    {
                        "first": "Kate",
                        "middle": [],
                        "last": "Mccurdy",
                        "suffix": ""
                    },
                    {
                        "first": "Adina",
                        "middle": [],
                        "last": "Williams",
                        "suffix": ""
                    },
                    {
                        "first": "Dieuwke",
                        "middle": [],
                        "last": "Hupkes",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 25th Conference on Computational Natural Language Learning",
                "volume": "",
                "issue": "",
                "pages": "94--108",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.conll-1.8"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Verna Dankers, Anna Langedijk, Kate McCurdy, Adina Williams, and Dieuwke Hupkes. 2021. Generalis- ing to German plural noun classes, from the perspec- tive of a recurrent neural network. In Proceedings of the 25th Conference on Computational Natural Lan- guage Learning, pages 94-108, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Cognitive science in the era of artificial intelligence: A roadmap for reverseengineering the infant language-learner",
                "authors": [
                    {
                        "first": "Emmanuel",
                        "middle": [],
                        "last": "Dupoux",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Cognition",
                "volume": "173",
                "issue": "",
                "pages": "43--59",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Emmanuel Dupoux. 2018. Cognitive science in the era of artificial intelligence: A roadmap for reverse- engineering the infant language-learner. Cognition, 173:43-59.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "The unreasonable volatility of neural machine translation models",
                "authors": [
                    {
                        "first": "Marzieh",
                        "middle": [],
                        "last": "Fadaee",
                        "suffix": ""
                    },
                    {
                        "first": "Christof",
                        "middle": [],
                        "last": "Monz",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the Fourth Workshop on Neural Generation and Translation, NGT@ACL 2020",
                "volume": "",
                "issue": "",
                "pages": "88--96",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.ngt-1.10"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Marzieh Fadaee and Christof Monz. 2020. The unrea- sonable volatility of neural machine translation mod- els. In Proceedings of the Fourth Workshop on Neu- ral Generation and Translation, NGT@ACL 2020, Online, July 5-10, 2020, pages 88-96. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Improving text-to-SQL evaluation methodology",
                "authors": [
                    {
                        "first": "Catherine",
                        "middle": [],
                        "last": "Finegan-Dollak",
                        "suffix": ""
                    },
                    {
                        "first": "Jonathan",
                        "middle": [
                            "K"
                        ],
                        "last": "Kummerfeld",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Karthik",
                        "middle": [],
                        "last": "Ramanathan",
                        "suffix": ""
                    },
                    {
                        "first": "Sesh",
                        "middle": [],
                        "last": "Sadasivam",
                        "suffix": ""
                    },
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Dragomir",
                        "middle": [],
                        "last": "Radev",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "351--360",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Catherine Finegan-Dollak, Jonathan K Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, and Dragomir Radev. 2018. Improving text-to-SQL evaluation methodology. In Proceed- ings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa- pers), pages 351-360.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Connectionism and cognitive architecture: A critical analysis",
                "authors": [
                    {
                        "first": "Jerry",
                        "middle": [
                            "A"
                        ],
                        "last": "Fodor",
                        "suffix": ""
                    },
                    {
                        "first": "Zenon",
                        "middle": [
                            "W"
                        ],
                        "last": "Pylyshyn",
                        "suffix": ""
                    }
                ],
                "year": 1988,
                "venue": "Cognition",
                "volume": "28",
                "issue": "1-2",
                "pages": "3--71",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jerry A Fodor and Zenon W Pylyshyn. 1988. Connec- tionism and cognitive architecture: A critical analy- sis. Cognition, 28(1-2):3-71.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Open Compositionality: Toward a New Methodology of Language",
                "authors": [
                    {
                        "first": "Eduardo",
                        "middle": [],
                        "last": "Garc\u00eda-Ram\u00edrez",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eduardo Garc\u00eda-Ram\u00edrez. 2019. Open Compositional- ity: Toward a New Methodology of Language. Row- man & Littlefield.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "The FLORES-101 evaluation benchmark for low-resource and multilingual machine translation",
                "authors": [
                    {
                        "first": "Naman",
                        "middle": [],
                        "last": "Goyal",
                        "suffix": ""
                    },
                    {
                        "first": "Cynthia",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Vishrav",
                        "middle": [],
                        "last": "Chaudhary",
                        "suffix": ""
                    },
                    {
                        "first": "Peng-Jen",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Guillaume",
                        "middle": [],
                        "last": "Wenzek",
                        "suffix": ""
                    },
                    {
                        "first": "Da",
                        "middle": [],
                        "last": "Ju",
                        "suffix": ""
                    },
                    {
                        "first": "Sanjana",
                        "middle": [],
                        "last": "Krishnan",
                        "suffix": ""
                    },
                    {
                        "first": "Marc'aurelio",
                        "middle": [],
                        "last": "Ranzato",
                        "suffix": ""
                    },
                    {
                        "first": "Francisco",
                        "middle": [],
                        "last": "Guzman",
                        "suffix": ""
                    },
                    {
                        "first": "Angela",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng- Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Kr- ishnan, Marc'Aurelio Ranzato, Francisco Guzman, and Angela Fan. 2021. The FLORES-101 evalu- ation benchmark for low-resource and multilingual machine translation. CoRR, abs/2106.03193.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Magpie: A large corpus of potentially idiomatic expressions",
                "authors": [
                    {
                        "first": "Hessel",
                        "middle": [],
                        "last": "Haagsma",
                        "suffix": ""
                    },
                    {
                        "first": "Johan",
                        "middle": [],
                        "last": "Bos",
                        "suffix": ""
                    },
                    {
                        "first": "Malvina",
                        "middle": [],
                        "last": "Nissim",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of The 12th Language Resources and Evaluation Conference",
                "volume": "",
                "issue": "",
                "pages": "279--287",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hessel Haagsma, Johan Bos, and Malvina Nissim. 2020. Magpie: A large corpus of potentially id- iomatic expressions. In Proceedings of The 12th Language Resources and Evaluation Conference, pages 279-287.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Compositionality decomposed: How do neural networks generalise",
                "authors": [
                    {
                        "first": "Dieuwke",
                        "middle": [],
                        "last": "Hupkes",
                        "suffix": ""
                    },
                    {
                        "first": "Verna",
                        "middle": [],
                        "last": "Dankers",
                        "suffix": ""
                    },
                    {
                        "first": "Mathijs",
                        "middle": [],
                        "last": "Mul",
                        "suffix": ""
                    },
                    {
                        "first": "Elia",
                        "middle": [],
                        "last": "Bruni",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Journal of Artificial Intellgence Research",
                "volume": "67",
                "issue": "",
                "pages": "757--795",
                "other_ids": {
                    "DOI": [
                        "10.1613/jair.1.11674"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, and Elia Bruni. 2020. Compositionality decomposed: How do neural networks generalise? Journal of Ar- tificial Intellgence Research, 67:757-795.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "The (dis)organization of the grammar: 25 years",
                "authors": [
                    {
                        "first": "Pauline",
                        "middle": [],
                        "last": "Jacobson",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Linguistics and Philosophy",
                "volume": "25",
                "issue": "5/6",
                "pages": "601--626",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pauline Jacobson. 2002. The (dis)organization of the grammar: 25 years. Linguistics and Philosophy, 25(5/6):601-626.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Algebraic translations, correctness and algebraic compiler construction",
                "authors": [
                    {
                        "first": "Theo Mv",
                        "middle": [],
                        "last": "Janssen",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Theoretical Computer Science",
                "volume": "199",
                "issue": "1-2",
                "pages": "25--56",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Theo MV Janssen. 1998. Algebraic translations, cor- rectness and algebraic compiler construction. Theo- retical Computer Science, 199(1-2):25-56.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Compositionality",
                "authors": [
                    {
                        "first": "M",
                        "middle": [
                            "V"
                        ],
                        "last": "Theo",
                        "suffix": ""
                    },
                    {
                        "first": "Barbara",
                        "middle": [
                            "H"
                        ],
                        "last": "Janssen",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Partee",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Handbook of logic and language",
                "volume": "",
                "issue": "",
                "pages": "417--473",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Theo MV Janssen and Barbara H Partee. 1997. Com- positionality. In Handbook of logic and language, pages 417-473. Elsevier.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Measuring compositional generalization: A comprehensive method on realistic data",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Keysers",
                        "suffix": ""
                    },
                    {
                        "first": "Nathanael",
                        "middle": [],
                        "last": "Sch\u00e4rli",
                        "suffix": ""
                    },
                    {
                        "first": "Nathan",
                        "middle": [],
                        "last": "Scales",
                        "suffix": ""
                    },
                    {
                        "first": "Hylke",
                        "middle": [],
                        "last": "Buisman",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Furrer",
                        "suffix": ""
                    },
                    {
                        "first": "Sergii",
                        "middle": [],
                        "last": "Kashubin",
                        "suffix": ""
                    },
                    {
                        "first": "Nikola",
                        "middle": [],
                        "last": "Momchev",
                        "suffix": ""
                    },
                    {
                        "first": "Danila",
                        "middle": [],
                        "last": "Sinopalnikov",
                        "suffix": ""
                    },
                    {
                        "first": "Lukasz",
                        "middle": [],
                        "last": "Stafiniak",
                        "suffix": ""
                    },
                    {
                        "first": "Tibor",
                        "middle": [],
                        "last": "Tihon",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, et al. 2019. Measuring com- positional generalization: A comprehensive method on realistic data. In International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "COGS: a compositional generalization challenge based on semantic interpretation",
                "authors": [
                    {
                        "first": "Najoung",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Tal",
                        "middle": [],
                        "last": "Linzen",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "9087--9105",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Najoung Kim and Tal Linzen. 2020. COGS: a composi- tional generalization challenge based on semantic in- terpretation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 9087-9105.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Transcoding compositionally: Using attention to find more generalizable solutions",
                "authors": [
                    {
                        "first": "Kris",
                        "middle": [],
                        "last": "Korrel",
                        "suffix": ""
                    },
                    {
                        "first": "Dieuwke",
                        "middle": [],
                        "last": "Hupkes",
                        "suffix": ""
                    },
                    {
                        "first": "Verna",
                        "middle": [],
                        "last": "Dankers",
                        "suffix": ""
                    },
                    {
                        "first": "Elia",
                        "middle": [],
                        "last": "Bruni",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "volume": "",
                "issue": "",
                "pages": "1--11",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W19-4801"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Kris Korrel, Dieuwke Hupkes, Verna Dankers, and Elia Bruni. 2019. Transcoding compositionally: Us- ing attention to find more generalizable solutions. In Proceedings of the 2019 ACL Workshop Black- boxNLP: Analyzing and Interpreting Neural Net- works for NLP, pages 1-11.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
                "authors": [
                    {
                        "first": "Brenden",
                        "middle": [],
                        "last": "Lake",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Baroni",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "International Conference on Machine Learning",
                "volume": "",
                "issue": "",
                "pages": "2873--2882",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Brenden Lake and Marco Baroni. 2018. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In In- ternational Conference on Machine Learning, pages 2873-2882. PMLR.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Human few-shot learning of compositional instructions",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Brenden",
                        "suffix": ""
                    },
                    {
                        "first": "Tal",
                        "middle": [],
                        "last": "Lake",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Linzen",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Baroni",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 41th Annual Meeting of the Cognitive Science Society, CogSci 2019: Creativity + Cognition + Computation",
                "volume": "",
                "issue": "",
                "pages": "611--617",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Brenden M. Lake, Tal Linzen, and Marco Baroni. 2019. Human few-shot learning of compositional instruc- tions. In Proceedings of the 41th Annual Meet- ing of the Cognitive Science Society, CogSci 2019: Creativity + Cognition + Computation, Montreal, Canada, July 24-27, 2019, pages 611-617. cogni- tivesciencesociety.org.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "The emergence of number and syntax units in LSTM language models",
                "authors": [
                    {
                        "first": "Yair",
                        "middle": [],
                        "last": "Lakretz",
                        "suffix": ""
                    },
                    {
                        "first": "German",
                        "middle": [],
                        "last": "Kruszewski",
                        "suffix": ""
                    },
                    {
                        "first": "Theo",
                        "middle": [],
                        "last": "Desbordes",
                        "suffix": ""
                    },
                    {
                        "first": "Dieuwke",
                        "middle": [],
                        "last": "Hupkes",
                        "suffix": ""
                    },
                    {
                        "first": "Stanislas",
                        "middle": [],
                        "last": "Dehaene",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Baroni",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "11--20",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-1002"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yair Lakretz, German Kruszewski, Theo Desbordes, Dieuwke Hupkes, Stanislas Dehaene, and Marco Ba- roni. 2019. The emergence of number and syn- tax units in LSTM language models. In Proceed- ings of the 2019 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 11-20.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "On compositional generalization of neural machine translation",
                "authors": [
                    {
                        "first": "Yafu",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Yongjing",
                        "middle": [],
                        "last": "Yin",
                        "suffix": ""
                    },
                    {
                        "first": "Yulong",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yue",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "4767--4780",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.acl-long.368"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yafu Li, Yongjing Yin, Yulong Chen, and Yue Zhang. 2021. On compositional generalization of neural machine translation. In Proceedings of the 59th An- nual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer- ence on Natural Language Processing (Volume 1: Long Papers), pages 4767-4780.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "The algebraic mind: Integrating connectionism and cognitive science",
                "authors": [
                    {
                        "first": "Marcus",
                        "middle": [],
                        "last": "Gary",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gary F Marcus. 2003. The algebraic mind: Integrating connectionism and cognitive science. MIT press.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization",
                "authors": [
                    {
                        "first": "Mathijs",
                        "middle": [],
                        "last": "Mul",
                        "suffix": ""
                    },
                    {
                        "first": "Willem",
                        "middle": [],
                        "last": "Zuidema",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mathijs Mul and Willem Zuidema. 2019. Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization. In CoRR, abs/1906.00180.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "A puzzle concerning compositionality in machines",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Ryan",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Nefdt",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Minds & Machines",
                "volume": "30",
                "issue": "1",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan M Nefdt. 2020. A puzzle concerning composi- tionality in machines. Minds & Machines, 30(1).",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "fairseq: A fast, extensible toolkit for sequence modeling",
                "authors": [
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Sergey",
                        "middle": [],
                        "last": "Edunov",
                        "suffix": ""
                    },
                    {
                        "first": "Alexei",
                        "middle": [],
                        "last": "Baevski",
                        "suffix": ""
                    },
                    {
                        "first": "Angela",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Gross",
                        "suffix": ""
                    },
                    {
                        "first": "Nathan",
                        "middle": [],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Grangier",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)",
                "volume": "",
                "issue": "",
                "pages": "48--53",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics (Demonstrations), pages 48-53.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Scaling neural machine translation",
                "authors": [
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Sergey",
                        "middle": [],
                        "last": "Edunov",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Grangier",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Third Conference on Machine Translation: Research Papers, WMT 2018",
                "volume": "",
                "issue": "",
                "pages": "1--9",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/w18-6301"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Myle Ott, Sergey Edunov, David Grangier, and Michael Auli. 2018. Scaling neural machine trans- lation. In Proceedings of the Third Conference on Machine Translation: Research Papers, WMT 2018, Belgium, Brussels, October 31 -November 1, 2018, pages 1-9. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Compositionality ii: Arguments and problems",
                "authors": [
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Pagin",
                        "suffix": ""
                    },
                    {
                        "first": "Dag",
                        "middle": [],
                        "last": "Westerst\u00e5hl",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Philosophy Compass",
                "volume": "5",
                "issue": "3",
                "pages": "265--282",
                "other_ids": {
                    "DOI": [
                        "10.1111/j.1747-9991.2009.00229.x?casa_token=iX-cpvt5tBsAAAAA:hFClgEse1miys7emGrHni3MKsi3RdwA-olea7c1Joo3I4XJQyLrI6aEu_gAbfVoKpWew4Bja9OrhOEk"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Peter Pagin and Dag Westerst\u00e5hl. 2010. Composition- ality ii: Arguments and problems. Philosophy Com- pass, 5(3):265-282.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Compositionality. Varieties of formal semantics",
                "authors": [
                    {
                        "first": "Barbara",
                        "middle": [],
                        "last": "Partee",
                        "suffix": ""
                    }
                ],
                "year": 1984,
                "venue": "",
                "volume": "3",
                "issue": "",
                "pages": "281--311",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Barbara Partee. 1984. Compositionality. Varieties of formal semantics, 3:281-311.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Sometimes we want ungrammatical translations",
                "authors": [
                    {
                        "first": "Prasanna",
                        "middle": [],
                        "last": "Parthasarathi",
                        "suffix": ""
                    },
                    {
                        "first": "Koustuv",
                        "middle": [],
                        "last": "Sinha",
                        "suffix": ""
                    },
                    {
                        "first": "Joelle",
                        "middle": [],
                        "last": "Pineau",
                        "suffix": ""
                    },
                    {
                        "first": "Adina",
                        "middle": [],
                        "last": "Williams",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021",
                "volume": "",
                "issue": "",
                "pages": "3205--3227",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Prasanna Parthasarathi, Koustuv Sinha, Joelle Pineau, and Adina Williams. 2021. Sometimes we want un- grammatical translations. In Findings of the Associ- ation for Computational Linguistics: EMNLP 2021, pages 3205-3227.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Most \"babies\" are \"little\" and most \"problems\" are \"huge\": Compositional entailment in adjective-nouns",
                "authors": [
                    {
                        "first": "Ellie",
                        "middle": [],
                        "last": "Pavlick",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "2164--2173",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ellie Pavlick and Chris Callison-Burch. 2016. Most \"babies\" are \"little\" and most \"problems\" are \"huge\": Compositional entailment in adjective-nouns. In Proceedings of the 54th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 2164-2173.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "The dual-mechanism debate",
                "authors": [
                    {
                        "first": "Martina",
                        "middle": [],
                        "last": "Penke",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "The Oxford handbook of compositionality",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.1093/oxfordhb/9780199541072.001.0001/oxfordhb-9780199541072-e-28"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Martina Penke. 2012. The dual-mechanism debate. In The Oxford handbook of compositionality.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "A call for clarity in reporting bleu scores",
                "authors": [
                    {
                        "first": "Matt",
                        "middle": [],
                        "last": "Post",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Third Conference on Machine Translation: Research Papers",
                "volume": "",
                "issue": "",
                "pages": "186--191",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matt Post. 2018. A call for clarity in reporting bleu scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186- 191.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "On compositionality in neural machine translation",
                "authors": [
                    {
                        "first": "Vaibhav",
                        "middle": [],
                        "last": "Vikas Raunak",
                        "suffix": ""
                    },
                    {
                        "first": "Florian",
                        "middle": [],
                        "last": "Kumar",
                        "suffix": ""
                    },
                    {
                        "first": "Jaimie",
                        "middle": [],
                        "last": "Metze",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Callan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "NeurIPS 2019 Context and Compositionality in Biological and Artificial Neural Systems Workshop",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vikas Raunak, Vaibhav Kumar, Florian Metze, and Jaimie Callan. 2019. On compositionality in neural machine translation. In NeurIPS 2019 Context and Compositionality in Biological and Artificial Neural Systems Workshop.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "The rosetta characteristics",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mt Rosetta",
                        "suffix": ""
                    }
                ],
                "year": 1994,
                "venue": "Compositional Translation",
                "volume": "",
                "issue": "",
                "pages": "85--102",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "MT Rosetta. 1994. The rosetta characteristics. In Com- positional Translation, pages 85-102. Springer.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "On Learning the Past Tenses of English Verbs",
                "authors": [
                    {
                        "first": "D E",
                        "middle": [],
                        "last": "Rumelhart",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Mcclelland",
                        "suffix": ""
                    }
                ],
                "year": 1986,
                "venue": "Parallel distributed processing: Explorations in the microstructure of cognition",
                "volume": "",
                "issue": "",
                "pages": "216--271",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D E Rumelhart and J McClelland. 1986. On Learning the Past Tenses of English Verbs. In Parallel dis- tributed processing: Explorations in the microstruc- ture of cognition, pages 216-271. MIT Press, Cam- bridge, MA.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "LSTMs compose-and Learn-Bottom-up",
                "authors": [
                    {
                        "first": "Naomi",
                        "middle": [],
                        "last": "Saphra",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Lopez",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "volume": "",
                "issue": "",
                "pages": "2797--2809",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.findings-emnlp.252"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Naomi Saphra and Adam Lopez. 2020. LSTMs compose-and Learn-Bottom-up. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 2797-2809, Online. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Compositional generalization and natural language variation: Can a semantic parsing approach handle both?",
                "authors": [
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Shaw",
                        "suffix": ""
                    },
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Panupong",
                        "middle": [],
                        "last": "Pasupat",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "922--938",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.acl-long.75"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova. 2021. Compositional general- ization and natural language variation: Can a se- mantic parsing approach handle both? In Proceed- ings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Interna- tional Joint Conference on Natural Language Pro- cessing (Volume 1: Long Papers), pages 922-938, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Tensor product variable binding and the representation of symbolic structures in connectionist systems",
                "authors": [
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Smolensky",
                        "suffix": ""
                    }
                ],
                "year": 1990,
                "venue": "Artificial intelligence",
                "volume": "46",
                "issue": "1-2",
                "pages": "159--216",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Paul Smolensky. 1990. Tensor product variable bind- ing and the representation of symbolic structures in connectionist systems. Artificial intelligence, 46(1- 2):159-216.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "The case for compositionality. The Oxford handbook of compositionality",
                "authors": [
                    {
                        "first": "Zoltan",
                        "middle": [],
                        "last": "Szab\u00f3",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "64",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zoltan Szab\u00f3. 2012. The case for compositionality. The Oxford handbook of compositionality, 64:80.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "The tatoeba translation challenge -realistic data sets for low resource and multilingual MT",
                "authors": [
                    {
                        "first": "J\u00f6rg",
                        "middle": [],
                        "last": "Tiedemann",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the Fifth Conference on Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "1174--1182",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J\u00f6rg Tiedemann. 2020. The tatoeba translation chal- lenge -realistic data sets for low resource and multi- lingual MT. In Proceedings of the Fifth Conference on Machine Translation, pages 1174-1182, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "OPUS-MT -building open translation services for the world",
                "authors": [
                    {
                        "first": "J\u00f6rg",
                        "middle": [],
                        "last": "Tiedemann",
                        "suffix": ""
                    },
                    {
                        "first": "Santhosh",
                        "middle": [],
                        "last": "Thottingal",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "479--480",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J\u00f6rg Tiedemann and Santhosh Thottingal. 2020. OPUS-MT -building open translation services for the world. In Proceedings of the 22nd Annual Con- ference of the European Association for Machine Translation, pages 479-480.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Data-oriented parsing with discontinuous constituents and function tags",
                "authors": [
                    {
                        "first": "Andreas",
                        "middle": [],
                        "last": "Van Cranenburgh",
                        "suffix": ""
                    },
                    {
                        "first": "Remko",
                        "middle": [],
                        "last": "Scha",
                        "suffix": ""
                    },
                    {
                        "first": "Rens",
                        "middle": [],
                        "last": "Bod",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Journal of Language Modelling",
                "volume": "4",
                "issue": "1",
                "pages": "57--111",
                "other_ids": {
                    "DOI": [
                        "10.15398/jlm.v4i1.100"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Andreas Van Cranenburgh, Remko Scha, and Rens Bod. 2016. Data-oriented parsing with discontinu- ous constituents and function tags. Journal of Lan- guage Modelling, 4(1):57-111.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Attention is all you need",
                "authors": [
                    {
                        "first": "Ashish",
                        "middle": [],
                        "last": "Vaswani",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Shazeer",
                        "suffix": ""
                    },
                    {
                        "first": "Niki",
                        "middle": [],
                        "last": "Parmar",
                        "suffix": ""
                    },
                    {
                        "first": "Jakob",
                        "middle": [],
                        "last": "Uszkoreit",
                        "suffix": ""
                    },
                    {
                        "first": "Llion",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Aidan",
                        "middle": [
                            "N"
                        ],
                        "last": "Gomez",
                        "suffix": ""
                    },
                    {
                        "first": "\u0141ukasz",
                        "middle": [],
                        "last": "Kaiser",
                        "suffix": ""
                    },
                    {
                        "first": "Illia",
                        "middle": [],
                        "last": "Polosukhin",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "5998--6008",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Pro- cessing Systems, pages 5998-6008.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "On the compositionality of idioms",
                "authors": [
                    {
                        "first": "Dag",
                        "middle": [],
                        "last": "Westerst\u00e5hl",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of LLC",
                "volume": "8",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dag Westerst\u00e5hl. 2002. On the compositionality of id- ioms. Proceedings of LLC8. CSLI Publications.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Systematicity results for setup S \u2192 S CONJ S (a and b) and S \u2192 NP VP (c and d). Consistency scores are shown per evaluation data type (x-axis) and training dataset size (colours). Data points represent templates (\u2022) and means over templates ( ).",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Illustration of the systematicity experiments S \u2192 S CONJ S (S 1 \u2192 S 3 is shown) and S \u2192 NP VP (both versions are shown). Each experiment involves extracting translations before and after the replacement of the blue part, and then comparing the translation of the underlined words.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 3: (a) Consistency scores of synonyms (averaged , and per synonym \u2022) for substitutivity per evaluation data type, for three training set sizes. (b) Consistency per synonym, measured using full sentences (in dark blue) or the synonym's translation only (in green), averaged over training dataset sizes and data types.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 4: Visualisation of overgeneralisation for idioms throughout training, with a line per idiom and the overall mean. Overgeneralisation occurs early on in training and precedes memorisation of idioms' translations. The colours indicate different training dataset sizes.",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            },
            "FIGREF4": {
                "num": null,
                "text": "Figure 5: Relative frequencies of manually labelled inconsistencies in translations, averaged over data types and training set sizes. The 'synonyms' distribution further details the category 'synonyms' from row two.",
                "uris": null,
                "fig_num": "5",
                "type_str": "figure"
            },
            "FIGREF6": {
                "num": null,
                "text": "88 .99 .56 .15 .81  medium .91 .60 .95 1.0 .78 .63 .96  1.0 1.0 .97 1.0 .31 .99 .99 1.0 .97 .74 .45 .30 .59 full .97 .55 .95 1.0 .40 .68 .99 1.0 1.0 .99 1.0 .31 1.0 .90 1.0 .97 .90 .25 .23 .47 natural small",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF7": {
                "num": null,
                "text": "Figure 6: Distribution of error types for sentences that contain inconsistencies in systematicity, detailed per model trained on the training set sizes in the subcaptions.",
                "uris": null,
                "fig_num": "6",
                "type_str": "figure"
            },
            "FIGREF8": {
                "num": null,
                "text": "Figure 7: Distribution of the types of inconsistencies observed in the substitutivity test, detailed per model trained on the training set sizes in the subcaptions. The red colour scheme represents error types specific to this experiment.",
                "uris": null,
                "fig_num": "7",
                "type_str": "figure"
            },
            "FIGREF9": {
                "num": null,
                "text": ": (. . . ) and in autumn 2005, five musicians join their forces and soon a couple of potential songs came into being in the rehearsal room. b. NL: (. . . ) in het najaar van 2005 voegen vijf muzikanten zich bij hun krachten en al snel kwamen er een paar potenti\u00eble nummers in de oefenruimte. c. NL: (. . . ) in het najaar van 2005 bundelen vijf muzikanten hun krachten en al snel komen er een paar potenti\u00eble nummers tot stand in de oefenruimte.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table/>",
                "type_str": "table",
                "text": "The synthetic and semi-natural templates, with POS tags of the lexical items varied shown in blue with the plurality as superscript and the subcategory as subscript. The OPUS-extracted NP and VP fragments are red.",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td>Data</td><td>Condition</td><td/><td>Model</td><td/><td/><td/><td/><td/><td colspan=\"2\">Template</td></tr><tr><td/><td/><td colspan=\"3\">small medium full</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9 10</td></tr><tr><td>S \u2192 NP VP</td><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>synthetic</td><td>NP</td><td>.73</td><td>.84</td><td>.84</td><td/><td/><td/><td/><td/></tr><tr><td>synthetic</td><td>VP</td><td>.76</td><td>.87</td><td>.88</td><td/><td/><td/><td/><td/></tr><tr><td>semi-natural</td><td>NP</td><td>.63</td><td>.66</td><td>.64</td><td/><td/><td/><td/><td/></tr><tr><td>S \u2192 S CONJ S</td><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>synthetic</td><td>S 1</td><td>.81</td><td>.90</td><td>.92</td><td/><td/><td/><td/><td/></tr><tr><td>synthetic</td><td>S3</td><td>.53</td><td>.76</td><td>.82</td><td/><td/><td/><td/><td/></tr><tr><td>semi-natural</td><td>S 1</td><td>.65</td><td>.73</td><td>.76</td><td/><td/><td/><td/><td/></tr><tr><td>semi-natural</td><td>S3</td><td>.29</td><td>.49</td><td>.49</td><td/><td/><td/><td/><td/></tr><tr><td>natural</td><td>S 1</td><td>.58</td><td>.67</td><td>.72</td><td/><td/><td/><td/><td/></tr><tr><td>natural</td><td>S3</td><td>.25</td><td>.39</td><td>.47</td><td/><td/><td/><td/><td/></tr><tr><td colspan=\"4\">(a) Per models' training set size</td><td/><td/><td/><td/><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Table 4 provides the numerical counterparts of the results visualised in Figure 1.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Consistency scores for the systematicity experiments, detailed per experimental setup and evaluation data type. We provide scores (a) per models' training set size, and (b) per template of our generated evaluation data. For natural data, the template number is meaningless, apart from the fact that it determines sentence length and word frequency.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td>Synonym pair</td><td/><td/><td/><td colspan=\"2\">Dutch translation Subordinate clause</td></tr><tr><td>British</td><td>Freq.</td><td>American</td><td>Freq.</td><td/><td/></tr><tr><td>aeroplane</td><td>6728</td><td>airplane</td><td>5403</td><td>vliegtuig</td><td>that travels by . . .</td></tr><tr><td>aluminium</td><td>17982</td><td>aluminum</td><td>5700</td><td>aluminium</td><td>that sells . . .</td></tr><tr><td>doughnut</td><td>2014</td><td>donut</td><td>1889</td><td>donut</td><td>that eats the . . .</td></tr><tr><td>foetus</td><td>1943</td><td>fetus</td><td>1878</td><td>foetus</td><td>that researches the . . .</td></tr><tr><td>flautist</td><td>112</td><td>flutist</td><td>101</td><td>fluitist</td><td>that knows the . . .</td></tr><tr><td>moustache</td><td>1132</td><td>mustache</td><td>1639</td><td>snor</td><td>that has a . . .</td></tr><tr><td>tumour</td><td>7338</td><td>tumor</td><td>6348</td><td>tumor</td><td>that has a . . .</td></tr><tr><td>pyjamas</td><td>808</td><td>pajamas</td><td>1106</td><td>pyjama</td><td>that wears . . .</td></tr><tr><td>sulphate</td><td>3776</td><td>sulfate</td><td>1143</td><td>zwavel</td><td>that sells . . .</td></tr><tr><td>yoghurt</td><td>1467</td><td>yogurt</td><td>2070</td><td>yoghurt</td><td>that eats the . . .</td></tr><tr><td>aubergine</td><td>765</td><td>eggplant</td><td>762</td><td>aubergine</td><td>that eats the . . .</td></tr><tr><td>shopping trolley</td><td>217</td><td colspan=\"3\">shopping cart 13366 winkelwagen</td><td>that uses a . . .</td></tr><tr><td colspan=\"2\">veterinary surgeon 941</td><td>veterinarian</td><td>6995</td><td>dierenarts</td><td>that knows the . . .</td></tr><tr><td>sailing boat</td><td>5097</td><td>sailboat</td><td>1977</td><td>zeilboot</td><td>that owns a . . .</td></tr><tr><td>football</td><td>33125</td><td>soccer</td><td>6841</td><td>voetbal</td><td>that plays . . .</td></tr><tr><td>holiday</td><td colspan=\"2\">125430 vacation</td><td colspan=\"2\">23532 vakantie</td><td>that enjoys the . . .</td></tr><tr><td>ladybird</td><td>235</td><td>ladybug</td><td>303</td><td>lieveheersbeestje</td><td>that caught a . . .</td></tr><tr><td>theatre</td><td>19451</td><td>theater</td><td colspan=\"2\">13508 theater</td><td>that loves . . .</td></tr><tr><td>postcode</td><td>479</td><td>zip code</td><td>1392</td><td>postcode</td><td>with the same . . .</td></tr><tr><td>whisky</td><td>3604</td><td>whiskey</td><td>4313</td><td>whisky</td><td>that drinks . . .</td></tr></table>",
                "type_str": "table",
                "text": "Table 6 further details the results from the figure, by presenting the average consistency per evaluation data type and training set size, and per evaluation data type and synonym pair.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td/><td/><td/><td colspan=\"2\">Data</td><td/><td colspan=\"2\">Metric</td><td/><td/><td colspan=\"2\">Model</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/><td colspan=\"5\">small medium full</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td colspan=\"2\">synthetic</td><td/><td colspan=\"2\">con.</td><td/><td>.49</td><td/><td>.67</td><td colspan=\"2\">.76</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td/><td colspan=\"4\">syn. con. .67</td><td/><td>.82</td><td colspan=\"2\">.93</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td colspan=\"5\">semi-natural con.</td><td/><td>.34</td><td/><td>.55</td><td colspan=\"2\">.62</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td/><td colspan=\"4\">syn. con. .62</td><td/><td>.84</td><td colspan=\"2\">.93</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td colspan=\"2\">natural</td><td/><td colspan=\"2\">con.</td><td/><td>.37</td><td/><td>.52</td><td colspan=\"2\">.63</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td/><td colspan=\"4\">syn. con. .61</td><td/><td>.75</td><td colspan=\"2\">.85</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td colspan=\"8\">(a) Per models' training set size</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>Data</td><td>Metric</td><td/><td/><td/><td/><td/><td/><td/><td/><td colspan=\"2\">Synonym</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>aeroplane</td><td>aluminium</td><td>doughnut</td><td>foetus</td><td>flautist</td><td>moustache</td><td>tumour</td><td>pyjamas</td><td>sulphate</td><td>yoghurt</td><td>aubergine</td><td>shopping trolley</td><td>veterinary surgeon</td><td>sailing boat</td><td>football</td><td>holiday</td><td>ladybird</td><td>theatre</td><td>postcode</td><td>whisky</td></tr><tr><td>synthetic</td><td>con.</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Synonyms for the substitutivity test, along with their OPUS frequency, Dutch translation, and the subordinate clause used to insert them in the data.",
                "html": null,
                "num": null
            },
            "TABREF6": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Consistency scores for the substitutivity experiments, detailed per evaluation data type. We present scores (a) per models' training set size and (b) per synonym.",
                "html": null,
                "num": null
            },
            "TABREF7": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Maximum overgeneralisation observed over the course of training, per evaluation data type, training set size and idiom.",
                "html": null,
                "num": null
            },
            "TABREF8": {
                "content": "<table><tr><td colspan=\"4\">Training set size Seed BLEU dev BLEU devtest</td></tr><tr><td>small</td><td>1</td><td>20.92</td><td>21.14</td></tr><tr><td/><td>2</td><td>20.77</td><td>20.37</td></tr><tr><td/><td>3</td><td>20.42</td><td>20.11</td></tr><tr><td/><td>4</td><td>20.95</td><td>20.23</td></tr><tr><td/><td>5</td><td>20.88</td><td>20.84</td></tr><tr><td>medium</td><td>1</td><td>24.09</td><td>24.18</td></tr><tr><td/><td>2</td><td>25.05</td><td>24.71</td></tr><tr><td/><td>3</td><td>24.55</td><td>24.42</td></tr><tr><td/><td>4</td><td>24.09</td><td>23.93</td></tr><tr><td/><td>5</td><td>24.55</td><td>24.10</td></tr><tr><td>full</td><td>1</td><td>26.17</td><td>25.63</td></tr><tr><td/><td>2</td><td>25.71</td><td>25.63</td></tr><tr><td/><td>3</td><td>25.82</td><td>25.72</td></tr><tr><td/><td>4</td><td>26.19</td><td>25.84</td></tr><tr><td/><td>5</td><td>25.86</td><td>25.76</td></tr></table>",
                "type_str": "table",
                "text": "BLEU scores for the 'dev' and 'devtest' subsets of the FLORES datasets, for models trained on corpora of three sizes, for five seeds per training set size.",
                "html": null,
                "num": null
            }
        }
    }
}